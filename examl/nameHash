axml.c:   for(model = 0; model < tr->NumberOfModels; model++)
axml.c:     tr->td[0].executeModel[model] = tr->executeModel[model];
axml.c:   for(model = 0; model < tr->NumberOfModels; model++)
axml.c:     tr->td[0].parameterValues[model] = value[model];
axml.c:  tr->bigCutoff = FALSE;
axml.c:  tr->maxCategories = MAX(4, tr->categories);
axml.c:  tr->partitionContributions = (double *)malloc(sizeof(double) * (size_t)tr->NumberOfModels);
axml.c:  tr->partitionWeights       = (double *)malloc(sizeof(double) * (size_t)tr->NumberOfModels);
axml.c:  for(i = 0; i < tr->NumberOfModels; i++)
axml.c:      tr->partitionContributions[i] = -1.0;
axml.c:      tr->partitionWeights[i] = -1.0;
axml.c:  tr->perPartitionLH = (double *)malloc(sizeof(double) * (size_t)tr->NumberOfModels);
axml.c:  for(i = 0; i < tr->NumberOfModels; i++)    
axml.c:    tr->perPartitionLH[i] = 0.0;	    
axml.c:  tips  = tr->mxtips;
axml.c:  inter = tr->mxtips - 1;
axml.c:  tr->fracchanges  = (double *)malloc((size_t)tr->NumberOfModels * sizeof(double));
axml.c:  tr->rawFracchanges  = (double *)malloc((size_t)tr->NumberOfModels * sizeof(double));
axml.c:  tr->treeStringLength = tr->mxtips * (nmlngth+128) + 256 + tr->mxtips * 2;
axml.c:  tr->tree_string  = (char*)calloc((size_t)tr->treeStringLength, sizeof(char)); 
axml.c:  tr->tree0 = (char*)calloc((size_t)tr->treeStringLength, sizeof(char));
axml.c:  tr->tree1 = (char*)calloc((size_t)tr->treeStringLength, sizeof(char));
axml.c:  tr->td[0].count = 0;
axml.c:  tr->td[0].ti    = (traversalInfo *)malloc(sizeof(traversalInfo) * tr->mxtips);
axml.c:  tr->td[0].executeModel = (boolean *)malloc(sizeof(boolean) * tr->NumberOfModels);
axml.c:  tr->td[0].parameterValues = (double *)malloc(sizeof(double) * tr->NumberOfModels);
axml.c:  for(i = 0; i < tr->NumberOfModels; i++)
axml.c:      tr->fracchanges[i] = -1.0;
axml.c:      tr->rawFracchanges[i] = -1.0;
axml.c:  tr->fracchange = -1.0;
axml.c:  tr->rawFracchange = -1.0;
axml.c:  tr->constraintVector = (int *)malloc((2 * tr->mxtips) * sizeof(int));
axml.c:  tr->nodeBaseAddress = p0;
axml.c:  if (!(tr->nodep = (nodeptr *) malloc((2*tr->mxtips) * sizeof(nodeptr))))
axml.c:  tr->nodep[0] = (node *) NULL;    /* Use as 1-based array */
axml.c:      tr->nodep[i] = p;
axml.c:      tr->nodep[i] = p;
axml.c:  tr->likelihood  = unlikely;
axml.c:  tr->start       = (node *) NULL;  
axml.c:  tr->ntips       = 0;
axml.c:  tr->nextnode    = 0;
axml.c:  for(i = 0; i < tr->numBranches; i++)
axml.c:    tr->partitionSmoothed[i] = FALSE;
axml.c:  tr->bitVectors = (unsigned int **)NULL;
axml.c:  tr->vLength = 0;
axml.c:  tr->h = (hashtable*)NULL;
axml.c:  tr->nameHash = initStringHashTable(10 * tr->mxtips);
axml.c:      tr->rateHetModel = CAT;
axml.c:      tr->rateHetModel = GAMMA;
axml.c:  tr->doCutoff = TRUE;
axml.c:  tr->secondaryStructureModel = SEC_16; /* default setting */
axml.c:  tr->searchConvergenceCriterion = FALSE;
axml.c:  tr->rateHetModel = GAMMA;
axml.c:  tr->multiStateModel  = GTR_MULTI_STATE;
axml.c:  tr->useGappedImplementation = FALSE;
axml.c:  tr->saveMemory = FALSE;
axml.c:  tr->constraintTree = FALSE;
axml.c:  tr->fastTreeEvaluation = FALSE;
axml.c:  /* tr->manyPartitions = FALSE; */
axml.c:  tr->categories             = 25;
axml.c:  tr->gapyness               = 0.0; 
axml.c:  tr->saveBestTrees          = 0;
axml.c:  tr->useMedian = FALSE;
axml.c:  tr->autoProteinSelectionType = AUTO_ML;
axml.c:			tr->autoProteinSelectionType = AUTO_ML;
axml.c:			tr->autoProteinSelectionType = AUTO_BIC;
axml.c:			tr->autoProteinSelectionType = AUTO_AIC;
axml.c:			tr->autoProteinSelectionType = AUTO_AICC;
axml.c:	    sscanf(optarg,"%u", &(tr->randomSeed));
axml.c:	    tr->useMedian = TRUE;	
axml.c:	    sscanf(optarg,"%d", &(tr->saveBestTrees));
axml.c:	    if(tr->saveBestTrees < 0)
axml.c:	    tr->saveMemory = TRUE;
axml.c:	    tr->searchConvergenceCriterion = TRUE;	
axml.c:	    sscanf(optarg, "%d", &tr->categories);
axml.c:		tr->fastTreeEvaluation = TRUE;
axml.c:		tr->fastTreeEvaluation = FALSE;
axml.c:		tr->doCutoff = TRUE;
axml.c:		tr->doCutoff = FALSE;
axml.c:	    tr->constraintTree = TRUE;
axml.c:  if(tr->constraintTree)
axml.c:      if(tr->useMedian)
axml.c:      printBoth(infoFile, "\nAlignment has %zu distinct alignment patterns\n\n",  tr->originalCrunchedLength);
axml.c:      printBoth(infoFile, "Proportion of gaps and completely undetermined characters in this alignment: %3.2f%s\n", 100.0 * tr->gapyness, "%");
axml.c:	  printBoth(infoFile, "\nExaML %s tree evaluation mode\n\n", (tr->fastTreeEvaluation)?"fast":"slow");
axml.c:	printBoth(infoFile, "Using %d distinct models/data partitions with individual per partition branch length optimization\n\n\n", tr->NumberOfModels);
axml.c:	printBoth(infoFile, "Using %d distinct models/data partitions with joint branch length optimization\n\n\n", tr->NumberOfModels);	
axml.c:      if(tr->rateHetModel == GAMMA || tr->rateHetModel == GAMMA_I)
axml.c:	  printBoth(infoFile, "ML estimate of %d per site rate categories\n\n", tr->categories);
axml.c:      for(model = 0; model < tr->NumberOfModels; model++)
axml.c:	  printBoth(infoFile, "Alignment Patterns: %d\n", tr->partitionData[model].upper - tr->partitionData[model].lower);
axml.c:	  printBoth(infoFile, "Name: %s\n", tr->partitionData[model].partitionName);
axml.c:	  switch(tr->partitionData[model].dataType)
axml.c:	      if(tr->partitionData[model].optimizeBaseFrequencies)
axml.c:	      assert(tr->partitionData[model].protModels >= 0 && tr->partitionData[model].protModels < NUM_PROT_MODELS);
axml.c:	      printBoth(infoFile, "Substitution Matrix: %s\n", protModels[tr->partitionData[model].protModels]);
axml.c:	      if(!tr->partitionData[model].optimizeBaseFrequencies)
axml.c:		printBoth(infoFile, "Using %s Base Frequencies\n", (tr->partitionData[model].protFreqs == 1)?"empirical":"fixed");	     
axml.c:		printBoth(infoFile, "Substitution Matrix: %s\n", secondaryModelList[tr->secondaryStructureModel]);
axml.c:		printBoth(infoFile, "Substitution Matrix: %s\n", secondaryModelList[tr->secondaryStructureModel]);
axml.c:		printBoth(infoFile, "Substitution Matrix: %s\n", secondaryModelList[tr->secondaryStructureModel]);
axml.c:		printBoth(infoFile, "DataType: Multi-State with %d distinct states in use (maximum 32)\n",tr->partitionData[model].states);		  
axml.c:		switch(tr->multiStateModel)
axml.c:	  Tree2String(tr->tree_string, tr, tr->start->back, TRUE, TRUE, FALSE, FALSE, finalPrint, SUMMARIZE_LH, FALSE, FALSE);
axml.c:	  fprintf(logFile, "%s", tr->tree_string);
axml.c:	      switch(tr->rateHetModel)
axml.c:		  Tree2String(tr->tree_string, tr, tr->start->back, TRUE, TRUE, FALSE, FALSE, finalPrint,
axml.c:		  fprintf(logFile, "%s", tr->tree_string);
axml.c:		  /*Tree2String(tr->tree_string, tr, tr->start->back, FALSE, TRUE, FALSE, FALSE, finalPrint, adef,
axml.c:		  Tree2String(tr->tree_string, tr, tr->start->back, TRUE, TRUE, FALSE, FALSE,
axml.c:		  fprintf(logFile, "%s", tr->tree_string);
axml.c:	      Tree2String(tr->tree_string, tr, tr->start->back, FALSE, TRUE, FALSE, FALSE, finalPrint,
axml.c:	      fprintf(logFile, "%s", tr->tree_string);
axml.c:      /* printf("%f %1.40f\n", t, tr->likelihood); */
axml.c:      fprintf(logFile, "%f %f\n", t, tr->likelihood);
axml.c:  switch(tr->partitionData[model].dataType)
axml.c:      strcat(typeOfData, secondaryModelList[tr->secondaryStructureModel]);
axml.c:      strcat(typeOfData, secondaryModelList[tr->secondaryStructureModel]);
axml.c:      strcat(typeOfData, secondaryModelList[tr->secondaryStructureModel]);
axml.c:  if(tr->numBranches == 1)             
axml.c:    x = -log(x) * tr->fracchange;       
axml.c:    x = -log(x) * tr->fracchanges[model];
axml.c:  if(isTip(p->number, tr->mxtips))  
axml.c:  return treeLengthRec(tr->start->back, tr, model);
axml.c:  for(model = 0; model < tr->NumberOfModels; model++)
axml.c:				 model, tr->partitionData[model].partitionName, typeOfData);
axml.c:      if(tr->rateHetModel == GAMMA)
axml.c:	printBothOpenDifferentFile(fileName, "alpha: %f\n", tr->partitionData[model].alpha);
axml.c:      f = tr->partitionData[model].frequencies;
axml.c:      r = tr->partitionData[model].substRates;
axml.c:      switch(tr->partitionData[model].dataType)
axml.c:	     if(tr->partitionData[model].protModels == LG4M || tr->partitionData[model].protModels == LG4X)
axml.c:		    printRatesRest(20, tr->partitionData[model].substRates_LG4[k], freqNames, fileName);
axml.c:		    printFreqs(20, tr->partitionData[model].frequencies_LG4[k], freqNames, fileName);
axml.c:	  printBothOpen("Likelihood   : %f\n", tr->likelihood);
axml.c:	  printBothOpen("\n\nOverall Time for evaluating the likelihhod of %d trees: %f secs\n\n", tr->numberOfTrees, t); 
axml.c:  compute_bits_in_16bits(tr->bits_in_16bits);
axml.c:  maxCategories = tr->maxCategories;
axml.c:  for(model = 0; model < tr->NumberOfModels; model++)
axml.c:	*pl = getPartitionLengths(&(tr->partitionData[model])); 
axml.c:      //and the subsequent copy of bf->partitions into tr->partitions!
axml.c:      assert(tr->partitionData[model].partitionName != (char*)NULL);
axml.c:      //printf("Partition name %s\n", tr->partitionData[model].partitionName);
axml.c:      width = tr->partitionData[model].width;
axml.c:	 globalScaler needs to be 2 * tr->mxtips such that scalers of inner AND tip nodes can be added without a case switch
axml.c:      len = 2 * tr->mxtips; 
axml.c:      tr->partitionData[model].globalScaler       = (unsigned int *)calloc(len, sizeof(unsigned int));
axml.c:      tr->partitionData[model].threadGlobalScaler = (unsigned int**) calloc(tr->nThreads, sizeof(unsigned int*));
axml.c:      tr->partitionData[model].reductionBuffer 	  = (double*) calloc(tr->nThreads, sizeof(double));
axml.c:      tr->partitionData[model].reductionBuffer2   = (double*) calloc(tr->nThreads, sizeof(double));
axml.c:      for (t = 0; t < tr->maxThreadsPerModel; ++t)
axml.c:	    pAss = tr->partThreadAssigns[model * tr->maxThreadsPerModel + t];
axml.c:	      tr->partitionData[model].threadGlobalScaler[tid]    = (unsigned int *)calloc(len, sizeof(unsigned int));
axml.c:      tr->partitionData[model].left              = (double *)malloc_aligned(pl->leftLength * (maxCategories + 1) * sizeof(double));
axml.c:      tr->partitionData[model].right             = (double *)malloc_aligned(pl->rightLength * (maxCategories + 1) * sizeof(double));
axml.c:      tr->partitionData[model].EIGN              = (double*)malloc(pl->eignLength * sizeof(double));
axml.c:      tr->partitionData[model].EV                = (double*)malloc_aligned(pl->evLength * sizeof(double));
axml.c:      tr->partitionData[model].EI                = (double*)malloc(pl->eiLength * sizeof(double));
axml.c:      tr->partitionData[model].substRates        = (double *)malloc(pl->substRatesLength * sizeof(double));
axml.c:      //and the subsequent copy of bf->partitions into tr->partitions!
axml.c:      assert(tr->partitionData[model].frequencies != (double*)NULL);
axml.c:      //tr->partitionData[model].frequencies       = (double*)malloc(pl->frequenciesLength * sizeof(double));
axml.c:      tr->partitionData[model].freqExponents     = (double*)malloc(pl->frequenciesLength * sizeof(double));
axml.c:      tr->partitionData[model].empiricalFrequencies       = (double*)malloc(pl->frequenciesLength * sizeof(double));
axml.c:      tr->partitionData[model].tipVector         = (double *)malloc_aligned(pl->tipVectorLength * sizeof(double));
axml.c:      if(tr->partitionData[model].protModels == LG4M || tr->partitionData[model].protModels == LG4X)      
axml.c:	      tr->partitionData[model].EIGN_LG4[k]              = (double*)malloc(pl->eignLength * sizeof(double));
axml.c:	      tr->partitionData[model].EV_LG4[k]                = (double*)malloc_aligned(pl->evLength * sizeof(double));
axml.c:	      tr->partitionData[model].EI_LG4[k]                = (double*)malloc(pl->eiLength * sizeof(double));
axml.c:	      tr->partitionData[model].substRates_LG4[k]        = (double *)malloc(pl->substRatesLength * sizeof(double));
axml.c:	      tr->partitionData[model].frequencies_LG4[k]       = (double*)malloc(pl->frequenciesLength * sizeof(double));
axml.c:	      tr->partitionData[model].tipVector_LG4[k]         = (double *)malloc_aligned(pl->tipVectorLength * sizeof(double));
axml.c:      tr->partitionData[model].symmetryVector    = (int *)malloc(pl->symmetryVectorLength  * sizeof(int));
axml.c:      tr->partitionData[model].frequencyGrouping = (int *)malloc(pl->frequencyGroupingLength  * sizeof(int));
axml.c:      tr->partitionData[model].perSiteRates      = (double *)malloc(sizeof(double) * tr->maxCategories);
axml.c:      //      tr->partitionData[model].nonGTR = FALSE; 
axml.c:      //      tr->partitionData[model].optimizeBaseFrequencies = FALSE; 
axml.c:      //tr->partitionData[model].gammaRates = (double*)malloc(sizeof(double) * 4);
axml.c:      tr->partitionData[model].xVector = (double **)malloc(sizeof(double*) * tr->mxtips);   
axml.c:      for(j = 0; j < (size_t)tr->mxtips; j++)	        	  	  	  	 
axml.c:	  tr->partitionData[model].xVector[j]   = (double*)NULL;   
axml.c:      tr->partitionData[model].xSpaceVector = (size_t *)calloc(tr->mxtips, sizeof(size_t));  
axml.c:      tr->partitionData[model].mic_EV                = (double*)malloc_aligned(4 * pl->evLength * sizeof(double));
axml.c:      tr->partitionData[model].mic_tipVector         = (double*)malloc_aligned(4 * pl->tipVectorLength * sizeof(double));
axml.c:      tr->partitionData[model].mic_umpLeft           = (double*)malloc_aligned(4 * pl->tipVectorLength * sizeof(double));
axml.c:      tr->partitionData[model].mic_umpRight           = (double*)malloc_aligned(4 * pl->tipVectorLength * sizeof(double));
axml.c:      const int span = (size_t)(tr->partitionData[model].states) *
axml.c:              discreteRateCategories(tr->rateHetModel);
axml.c:      tr->partitionData[model].sumBuffer = (double *)malloc_aligned(padded_width *
axml.c:              tr->partitionData[model].sumBuffer[k] = 1.;
axml.c:      tr->partitionData[model].sumBuffer = (double *)malloc_aligned(width *
axml.c:									   (size_t)(tr->partitionData[model].states) *
axml.c:									   discreteRateCategories(tr->rateHetModel) *
axml.c:      /* tr->partitionData[model].wgt = (int *)malloc_aligned(width * sizeof(int));	   */
axml.c:      if(width > 0 && tr->saveMemory)
axml.c:	  tr->partitionData[model].gapVectorLength = ((int)width / 32) + 1;
axml.c:	  len = tr->partitionData[model].gapVectorLength * 2 * tr->mxtips; 
axml.c:	  tr->partitionData[model].gapVector = (unsigned int*)calloc(len, sizeof(unsigned int));	  	    	  	  
axml.c:	  tr->partitionData[model].gapColumn = (double *)malloc_aligned(((size_t)tr->mxtips) *								      
axml.c:									       ((size_t)(tr->partitionData[model].states)) *
axml.c:									       discreteRateCategories(tr->rateHetModel) * sizeof(double));
axml.c:	   tr->partitionData[model].gapVectorLength = 0;
axml.c:	   tr->partitionData[model].gapVector = (unsigned int*)NULL; 	  	    	   
axml.c:	   tr->partitionData[model].gapColumn = (double*)NULL;	    	    	   
axml.c:      *modelWeights = (unsigned long*) calloc(tr->NumberOfModels, sizeof(unsigned long)); 
axml.c:    for(model = 0; model < tr->NumberOfModels; model++)      
axml.c:	  partition =  tr->partitionData[model] ; 
axml.c:    MPI_Allreduce(MPI_IN_PLACE, modelWeights, tr->NumberOfModels, MPI_UNSIGNED_LONG, MPI_SUM, MPI_COMM_WORLD); 
axml.c:    for(model = 0; model < tr->NumberOfModels; ++model)
axml.c:    for(model = 0; model < tr->NumberOfModels; model++)      	
axml.c:	tr->partitionWeights[model]       = (double)modelWeights[model];
axml.c:	tr->partitionContributions[model] = ((double)modelWeights[model]) / ((double)wgtsum); 
axml.c:  if(tr->saveMemory)
axml.c:      for(model = 0; model <tr->NumberOfModels; model++)
axml.c:	    undetermined = getUndetermined(tr->partitionData[model].dataType);
axml.c:	  width =  tr->partitionData[model].width;
axml.c:	      for(j = 1; j <= (size_t)(tr->mxtips); j++)
axml.c:		  if(tr->partitionData[model].yVector[j][i] == undetermined)
axml.c:		    tr->partitionData[model].gapVector[tr->partitionData[model].gapVectorLength * j + i / 32] |= mask32[i % 32];	    
axml.c:    tr->numBranches = tr->NumberOfModels;
axml.c:    tr->numBranches = 1;
axml.c:  if(NUM_BRANCHES < tr->numBranches)
axml.c:	       tr->NumberOfModels,tr->NumberOfModels, programName );
axml.c:  tr->executeModel   = (boolean *)calloc( tr->NumberOfModels, sizeof(boolean));
axml.c:  for(i = 0; i < (size_t)tr->NumberOfModels; i++)
axml.c:    tr->executeModel[i] = TRUE;
axml.c:  if(tr->searchConvergenceCriterion && processID == 0)
axml.c:      tr->bitVectors = initBitVector(tr->mxtips, &(tr->vLength));
axml.c:      tr->h = initHashTable(tr->mxtips * 4);     
axml.c:  for(i = 1; i <= (size_t)tr->mxtips; i++)
axml.c:    addword(tr->nameList[i], tr->nameHash, i);
axml.c:  tr->numberOfTrees = getNumberOfTrees(tree_file, FALSE, (exa_off_t *)NULL);
axml.c:  treeOffsets = (exa_off_t *)malloc(sizeof(exa_off_t) * (tr->numberOfTrees + 1));
axml.c:  tr->likelihoods = (double *)malloc(sizeof(double) * tr->numberOfTrees);
axml.c:  tr->treeStrings = (char   *)malloc(sizeof(char) * (size_t)tr->treeStringLength * (size_t)tr->numberOfTrees);
axml.c:    printBothOpen("\n\nFound %d trees to evaluate\n\n", tr->numberOfTrees);
axml.c:      if(tr->fastTreeEvaluation && i > 0)	
axml.c:      tr->likelihoods[i] = tr->likelihood;
axml.c:      Tree2String(tr->tree_string, tr, tr->start->back, TRUE, TRUE, FALSE, FALSE, FALSE, SUMMARIZE_LH, FALSE, FALSE);
axml.c:      memcpy(&(tr->treeStrings[(size_t)tr->treeStringLength * (size_t)i]), tr->tree_string, sizeof(char) * tr->treeStringLength);
axml.c:  for(; i < tr->numberOfTrees; i++)
axml.c:      tr->likelihood = unlikely;
axml.c:      tr->start = tr->nodep[1];     
axml.c:      evaluateGeneric(tr, tr->start, TRUE);	
axml.c:      if(tr->fastTreeEvaluation && i > 0)
axml.c:      tr->likelihoods[i] = tr->likelihood;
axml.c:      Tree2String(tr->tree_string, tr, tr->start->back, TRUE, TRUE, FALSE, FALSE, FALSE, SUMMARIZE_LH, FALSE, FALSE);
axml.c:      memcpy(&(tr->treeStrings[(size_t)tr->treeStringLength * (size_t)i]), tr->tree_string, sizeof(char) * tr->treeStringLength);
axml.c:      for(i = 0; i < tr->numberOfTrees; i++)
axml.c:	  printBothOpen("Likelihood tree %d: %f \n", i, tr->likelihoods[i]);    
axml.c:	  fprintf(f, "%s", &(tr->treeStrings[(size_t)tr->treeStringLength * (size_t)i]));
axml.c:  /* just fills up tr->partAssigns that contains the representation of
axml.c:    p = tr->start,
axml.c:  tr->td[0].ti[0].pNumber = p->number;
axml.c:  tr->td[0].ti[0].qNumber = q->number;
axml.c:  tr->td[0].count = 1;
axml.c:  computeTraversalInfo(q, &(tr->td[0].ti[0]), &(tr->td[0].count), tr->mxtips, tr->numBranches, FALSE);
axml.c:    *ti = tr->td[0].ti;
axml.c:  for(i = 1; i < tr->td[0].count; i++)
axml.c:      for(model = 0; model < tr->NumberOfModels; model++)
axml.c:	    width  = (size_t)tr->partitionData[model].width;
axml.c:	    *x3_start = tr->partitionData[model].xVector[tInfo->pNumber - tr->mxtips - 1];
axml.c:	    rateHet = discreteRateCategories(tr->rateHetModel),
axml.c:	    states = (size_t)tr->partitionData[model].states,
axml.c:	       So tr->partitionData[model].xSpaceVector[i] provides the length of the allocated conditional array of partition model
axml.c:	    availableLength = tr->partitionData[model].xSpaceVector[(tInfo->pNumber - tr->mxtips - 1)],
axml.c:	  if(tr->saveMemory)
axml.c:		*x1_gap = &(tr->partitionData[model].gapVector[tInfo->qNumber * tr->partitionData[model].gapVectorLength]),
axml.c:		*x2_gap = &(tr->partitionData[model].gapVector[tInfo->rNumber * tr->partitionData[model].gapVectorLength]),
axml.c:		*x3_gap = &(tr->partitionData[model].gapVector[tInfo->pNumber * tr->partitionData[model].gapVectorLength]);
axml.c:	      for(j = 0; j < (size_t)tr->partitionData[model].gapVectorLength; j++)
axml.c:		  setBits += (size_t)(precomputed16_bitcount(x3_gap[j], tr->bits_in_16bits));
axml.c:	      tr->partitionData[model].xVector[tInfo->pNumber - tr->mxtips - 1] = x3_start;
axml.c:	      tr->partitionData[model].xSpaceVector[(tInfo->pNumber - tr->mxtips - 1)] = requiredLength;
axml.c:  pInfo** rankPartitions = (pInfo **)calloc(tr->NumberOfModels, sizeof(pInfo*) );
axml.c:  for (i = 0; i < tr->NumberOfModels; ++i)
axml.c:    rankPartitions[i]->upper = tr->partitionData[i].width;
axml.c:    rankPartitions[i]->states = tr->partitionData[i].states;
axml.c:  initializePartitionAssignment(&pAss, rankPartitions, tr->NumberOfModels, tr->nThreads);
axml.c:  for (i = 0; i < tr->NumberOfModels; ++i)
axml.c:    if(tr->saveMemory)
axml.c:    tr->nThreads = omp_get_max_threads();
axml.c:	printBothOpen("Memory Saving Option: %s\n", (tr->saveMemory == TRUE)?"ENABLED":"DISABLED");   	             
axml.c:      if(tr->saveMemory)
axml.c:      if(tr->rateHetModel == CAT)
axml.c:      for(model = 0; model < tr->NumberOfModels; model++)
axml.c:	  if(tr->partitionData[model].protModels == LG4M ||  tr->partitionData[model].protModels == LG4X)
axml.c:	  if(tr->partitionData[model].states == 2)
axml.c:	  if(tr->saveMemory == TRUE)
axml.c:	  if(tr->rateHetModel == CAT)
axml.c:	  if(tr->saveMemory == TRUE)
axml.c:	    evaluateGeneric(tr, tr->start, TRUE);	       	  
byteFile.c:  tr->mxtips = bf->numTax;
byteFile.c:  tr->originalCrunchedLength = bf->numPattern; 
byteFile.c:  tr->NumberOfModels = bf->numPartitions; 
byteFile.c:  tr->gapyness = bf->gappyness; 
byteFile.c:  tr->nameList = (char **)calloc((size_t)(tr->mxtips + 1), sizeof(char *)  );
byteFile.c:  tr->nameList[0] = (char *)NULL;
byteFile.c:      tr->nameList[i] = (char*)calloc(strlen(bf->taxaNames[i-1]) + 1, sizeof(char)); 
byteFile.c:      strcpy(tr->nameList[i], bf->taxaNames[i-1]);      
byteFile.c:  tr->partitionData = (pInfo*)calloc(tr->NumberOfModels, sizeof(pInfo));
byteFile.c:  for(i = 0; i < tr->NumberOfModels; ++i)
byteFile.c:      tr->partitionData[i] = *(bf->partitions[i]);
byteFile.c:      myLength += tr->partitionData[i].width; 
byteFile.c:      assert( ( tr->partitionData[i].wgt != (int*)NULL)  || ( tr->partitionData[i].width == 0 ) ); 
communication.c:  for(i = 0; i < tr->numAssignments; ++i)
communication.c:      Assign* ass = &(tr->partAssigns[i]); 
communication.c:    tr->rateCategory) to partition-specfic arrays (e.g.,
communication.c:    tr->partitionData[i].rateCategory). 
communication.c:    This works, because tr->partitionData[i].rateCategory is a
communication.c:    (e.g., tr->rateCategory_basePtr).
communication.c:      srcReordered = (char *)malloc(tr->originalCrunchedLength * typeLen); 
communication.c:      Assign *aIter = tr->partAssigns; 
communication.c:      Assign *aEnd = &(tr->partAssigns[ tr->numAssignments ] ); 
communication.c:	  pInfo *partition = &(tr->partitionData[ aIter->partitionId ]) ; 
communication.c:    tr->rateCategory) to partition-specfic arrays (e.g.,
communication.c:    tr->partitionData[i].rateCategory).
communication.c:    This works, because tr->partitionData[i].rateCategory is a
communication.c:    (e.g., tr->rateCategory_basePtr).
communication.c:      *destinationPtr = (void *)malloc( tr->originalCrunchedLength *  typeLen); 
communication.c:      destinationUnordered = (char *)malloc( tr->originalCrunchedLength * typeLen); 
communication.c:    gathered tr->partitionData[i].lhs, then *destinationPtr
communication.c:    corresponds to what previously was tr->lhs). This strongly couples
communication.c:    the respective distributed array to tr->partAssigns.
communication.c:	*aIter = tr->partAssigns; 
communication.c:	*aEnd = tr->partAssigns + tr->numAssignments; 
communication.c:	    *partition  = &(tr->partitionData[aIter->partitionId]); 
evaluateGenericSpecial.c:    *pz = tr->td[0].ti[0].qz;   
evaluateGenericSpecial.c:    pNumber = tr->td[0].ti[0].pNumber, 
evaluateGenericSpecial.c:    qNumber = tr->td[0].ti[0].qNumber;
evaluateGenericSpecial.c:  for(m = 0; m < tr->NumberOfModels; m++)
evaluateGenericSpecial.c:	if(!tr->td[0].executeModel[m] || tr->partitionData[m].width == 0)
evaluateGenericSpecial.c:	  states = tr->partitionData[m].states;
evaluateGenericSpecial.c:	  *diagptable = tr->partitionData[m].left;
evaluateGenericSpecial.c:	if(tr->numBranches > 1)
evaluateGenericSpecial.c:	if(tr->rateHetModel == CAT)
evaluateGenericSpecial.c:	    rateCategories = tr->partitionData[m].perSiteRates;
evaluateGenericSpecial.c:	    categories = tr->partitionData[m].numberOfCategories;
evaluateGenericSpecial.c:	    rateCategories = tr->partitionData[m].gammaRates;
evaluateGenericSpecial.c:	if(tr->partitionData[m].protModels == LG4M || tr->partitionData[m].protModels == LG4X)
evaluateGenericSpecial.c:	  calcDiagptableFlex_LG4(z, 4, tr->partitionData[m].gammaRates, tr->partitionData[m].EIGN_LG4, diagptable, 20);
evaluateGenericSpecial.c:	  calcDiagptable(z, states, categories, rateCategories, tr->partitionData[m].EIGN, diagptable);
evaluateGenericSpecial.c:    maxModel = tr->maxModelsPerThread;
evaluateGenericSpecial.c:    maxModel = tr->NumberOfModels;
evaluateGenericSpecial.c:	    pAss = tr->threadPartAssigns[tid * tr->maxModelsPerThread + m];
evaluateGenericSpecial.c:	      assert(model < tr->NumberOfModels);
evaluateGenericSpecial.c:	      diagptable = tr->partitionData[model].left;
evaluateGenericSpecial.c:	      globalScaler = tr->partitionData[model].threadGlobalScaler[tid];
evaluateGenericSpecial.c:	      perPartitionLH = &tr->partitionData[model].reductionBuffer[tid];
evaluateGenericSpecial.c:	  width  = (size_t)tr->partitionData[model].width;
evaluateGenericSpecial.c:	  diagptable = tr->partitionData[model].left;
evaluateGenericSpecial.c:	  globalScaler = tr->partitionData[model].globalScaler;
evaluateGenericSpecial.c:	  perPartitionLH = &tr->perPartitionLH[model];
evaluateGenericSpecial.c:      if(tr->td[0].executeModel[model] && width > 0)
evaluateGenericSpecial.c:	    rateHet = (int)discreteRateCategories(tr->rateHetModel),
evaluateGenericSpecial.c:	    states = tr->partitionData[model].states,
evaluateGenericSpecial.c:	    *wgt = tr->partitionData[model].wgt + offset,
evaluateGenericSpecial.c:	    *rateCategory = tr->partitionData[model].rateCategory + offset;
evaluateGenericSpecial.c:	    *weights = tr->partitionData[model].weights,
evaluateGenericSpecial.c:	  if(isTip(pNumber, tr->mxtips) || isTip(qNumber, tr->mxtips))
evaluateGenericSpecial.c:	      if(isTip(qNumber, tr->mxtips))
evaluateGenericSpecial.c:		  x2_start = tr->partitionData[model].xVector[pNumber - tr->mxtips -1] + x_offset;
evaluateGenericSpecial.c:		  if(isPomo(tr->partitionData[model].dataType))		  
evaluateGenericSpecial.c:		      x1_start = tr->partitionData[model].xTipVector[qNumber];
evaluateGenericSpecial.c:		    tip      = tr->partitionData[model].yVector[qNumber] + offset;
evaluateGenericSpecial.c:		  if(tr->saveMemory)
evaluateGenericSpecial.c:		      x2_gap         = &(tr->partitionData[model].gapVector[pNumber * tr->partitionData[model].gapVectorLength]);
evaluateGenericSpecial.c:		      x2_gapColumn   = &(tr->partitionData[model].gapColumn[(pNumber - tr->mxtips - 1) * states * rateHet]);
evaluateGenericSpecial.c:		  x2_start = tr->partitionData[model].xVector[qNumber - tr->mxtips - 1] + x_offset;
evaluateGenericSpecial.c:		  if(isPomo(tr->partitionData[model].dataType))		  
evaluateGenericSpecial.c:		      x1_start = tr->partitionData[model].xTipVector[pNumber];
evaluateGenericSpecial.c:		    tip = tr->partitionData[model].yVector[pNumber] + offset;
evaluateGenericSpecial.c:		  if(tr->saveMemory)
evaluateGenericSpecial.c:		      x2_gap         = &(tr->partitionData[model].gapVector[qNumber * tr->partitionData[model].gapVectorLength]);
evaluateGenericSpecial.c:		      x2_gapColumn   = &(tr->partitionData[model].gapColumn[(qNumber - tr->mxtips - 1) * states * rateHet]);
evaluateGenericSpecial.c:	      if(isPomo(tr->partitionData[model].dataType))	
evaluateGenericSpecial.c:	      x1_start = tr->partitionData[model].xVector[pNumber - tr->mxtips - 1] + x_offset;
evaluateGenericSpecial.c:	      x2_start = tr->partitionData[model].xVector[qNumber - tr->mxtips - 1] + x_offset;
evaluateGenericSpecial.c:	      if(tr->saveMemory)
evaluateGenericSpecial.c:		  x1_gap = &(tr->partitionData[model].gapVector[pNumber * tr->partitionData[model].gapVectorLength]);
evaluateGenericSpecial.c:		  x2_gap = &(tr->partitionData[model].gapVector[qNumber * tr->partitionData[model].gapVectorLength]);
evaluateGenericSpecial.c:		  x1_gapColumn   = &tr->partitionData[model].gapColumn[(pNumber - tr->mxtips - 1) * states * rateHet];
evaluateGenericSpecial.c:		  x2_gapColumn   = &tr->partitionData[model].gapColumn[(qNumber - tr->mxtips - 1) * states * rateHet];
evaluateGenericSpecial.c:	  assert(!tr->saveMemory);
evaluateGenericSpecial.c:	  if(tr->rateHetModel == CAT)
evaluateGenericSpecial.c:	     partitionLikelihood = evaluateCAT_FLEX(tr->partitionData[model].rateCategory, wgt,
evaluateGenericSpecial.c:						    x1_start, x2_start, tr->partitionData[model].tipVector, 
evaluateGenericSpecial.c:						     x1_start, x2_start, tr->partitionData[model].tipVector,
evaluateGenericSpecial.c:	      assert(!tr->saveMemory);
evaluateGenericSpecial.c:	      if(tr->rateHetModel == CAT)
evaluateGenericSpecial.c:				      x1_start, x2_start, tr->partitionData[model].tipVector, 
evaluateGenericSpecial.c:							     tr->partitionData[model].tipVector,
evaluateGenericSpecial.c:		if(tr->rateHetModel == CAT)
evaluateGenericSpecial.c:		    if(tr->saveMemory)
evaluateGenericSpecial.c:								 x1_start, x2_start, tr->partitionData[model].tipVector, 
evaluateGenericSpecial.c:							    x1_start, x2_start, tr->partitionData[model].tipVector, 
evaluateGenericSpecial.c:		    if(tr->saveMemory)		   
evaluateGenericSpecial.c:									  x1_start, x2_start, tr->partitionData[model].tipVector,
evaluateGenericSpecial.c:	                                 x1_start, x2_start, tr->partitionData[model].mic_tipVector,
evaluateGenericSpecial.c:							      x1_start, x2_start, tr->partitionData[model].tipVector,
evaluateGenericSpecial.c:		if(tr->rateHetModel == CAT)
evaluateGenericSpecial.c:		    if(tr->saveMemory)
evaluateGenericSpecial.c:								    x1_start, x2_start, tr->partitionData[model].tipVector,
evaluateGenericSpecial.c:							       x1_start, x2_start, tr->partitionData[model].tipVector,
evaluateGenericSpecial.c:		    if(tr->saveMemory)
evaluateGenericSpecial.c:									     x1_start, x2_start, tr->partitionData[model].tipVector,
evaluateGenericSpecial.c:			if(tr->partitionData[model].protModels == LG4M || tr->partitionData[model].protModels == LG4X)
evaluateGenericSpecial.c:                               x1_start, x2_start, tr->partitionData[model].mic_tipVector,
evaluateGenericSpecial.c:									  x1_start, x2_start, tr->partitionData[model].tipVector_LG4,
evaluateGenericSpecial.c:	                               x1_start, x2_start, tr->partitionData[model].mic_tipVector,
evaluateGenericSpecial.c:								   x1_start, x2_start, tr->partitionData[model].tipVector,
evaluateGenericSpecial.c:	      assert(!tr->saveMemory);
evaluateGenericSpecial.c:							    x1_start, x2_start, tr->partitionData[model].tipVector,
evaluateGenericSpecial.c:	      assert(!tr->saveMemory);
evaluateGenericSpecial.c:							    x1_start, x2_start, tr->partitionData[model].tipVector,
evaluateGenericSpecial.c:	     That is, the values of tr->perPartitionLH across all threads 
evaluateGenericSpecial.c:	      assert(tr->td[0].executeModel[model] == FALSE && *perPartitionLH < 0.0);
evaluateGenericSpecial.c:  for(model = 0; model < tr->NumberOfModels; model++)
evaluateGenericSpecial.c:     if (!tr->td[0].executeModel[model])
evaluateGenericSpecial.c:      tr->perPartitionLH[model] = 0.0;
evaluateGenericSpecial.c:      for(t = 0; t < tr->maxThreadsPerModel; t++)
evaluateGenericSpecial.c:	    pAss = tr->partThreadAssigns[model * tr->maxThreadsPerModel + t];
evaluateGenericSpecial.c:	      tr->perPartitionLH[model] += tr->partitionData[model].reductionBuffer[tid];
evaluateGenericSpecial.c:  tr->td[0].ti[0].pNumber = p->number;
evaluateGenericSpecial.c:  tr->td[0].ti[0].qNumber = q->number;          
evaluateGenericSpecial.c:     if -M is not used tr->numBranches must be 1 */
evaluateGenericSpecial.c:  for(i = 0; i < tr->numBranches; i++)    
evaluateGenericSpecial.c:    tr->td[0].ti[0].qz[i] =  q->z[i];
evaluateGenericSpecial.c:  tr->td[0].count = 1;
evaluateGenericSpecial.c:      assert(isTip(p->number, tr->mxtips));
evaluateGenericSpecial.c:      computeTraversalInfo(q, &(tr->td[0].ti[0]), &(tr->td[0].count), tr->mxtips, tr->numBranches, FALSE);     
evaluateGenericSpecial.c:	computeTraversalInfo(p, &(tr->td[0].ti[0]), &(tr->td[0].count), tr->mxtips, tr->numBranches, TRUE);
evaluateGenericSpecial.c:	computeTraversalInfo(q, &(tr->td[0].ti[0]), &(tr->td[0].count), tr->mxtips, tr->numBranches, TRUE);  
evaluateGenericSpecial.c:  tr->td[0].traversalHasChanged = TRUE;
evaluateGenericSpecial.c:      *recv = (double *)malloc(sizeof(double) * tr->NumberOfModels);
evaluateGenericSpecial.c:    MPI_Allreduce(tr->perPartitionLH, recv, tr->NumberOfModels, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);
evaluateGenericSpecial.c:    MPI_Reduce(tr->perPartitionLH, recv, tr->NumberOfModels, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD);
evaluateGenericSpecial.c:    MPI_Bcast(recv, tr->NumberOfModels, MPI_DOUBLE, 0, MPI_COMM_WORLD);
evaluateGenericSpecial.c:    memcpy(tr->perPartitionLH, recv, tr->NumberOfModels * sizeof(double));
evaluateGenericSpecial.c:    for(model = 0; model < tr->NumberOfModels; model++)        
evaluateGenericSpecial.c:      result += tr->perPartitionLH[model];
evaluateGenericSpecial.c:  tr->likelihood = result;    
evaluateGenericSpecial.c:     printf("Process %d likelihood: %f\n", processID, tr->likelihood);
evaluateGenericSpecial.c:  tr->td[0].traversalHasChanged = FALSE;  
evaluatePartialGenericSpecial.c:    states = tr->partitionData[_model].states;
evaluatePartialGenericSpecial.c:  if(tr->numBranches > 1)
evaluatePartialGenericSpecial.c:  if(tr->rateHetModel == CAT)
evaluatePartialGenericSpecial.c:    result = evaluatePartialCAT_FLEX(index, ki, tr->td[0].count, tr->td[0].ti, tr->td[0].ti[0].qz[branchReference], 
evaluatePartialGenericSpecial.c:				     tr->partitionData[_model].wgt[index],
evaluatePartialGenericSpecial.c:				     tr->partitionData[_model].EIGN, 
evaluatePartialGenericSpecial.c:				     tr->partitionData[_model].EI, 
evaluatePartialGenericSpecial.c:				     tr->partitionData[_model].EV,
evaluatePartialGenericSpecial.c:				     tr->partitionData[_model].tipVector,
evaluatePartialGenericSpecial.c:				     tr->partitionData[_model].yVector, branchReference, tr->mxtips, states);
evaluatePartialGenericSpecial.c:if (tr->rateHetModel == CAT)
evaluatePartialGenericSpecial.c:    result = evaluatePartialCAT_FLEX(index, ki, tr->td[0].count, tr->td[0].ti, tr->td[0].ti[0].qz[branchReference],
evaluatePartialGenericSpecial.c:                     tr->partitionData[_model].wgt[index],
evaluatePartialGenericSpecial.c:                     tr->partitionData[_model].EIGN,
evaluatePartialGenericSpecial.c:                     tr->partitionData[_model].EI,
evaluatePartialGenericSpecial.c:                     tr->partitionData[_model].EV,
evaluatePartialGenericSpecial.c:                     tr->partitionData[_model].tipVector,
evaluatePartialGenericSpecial.c:                     tr->partitionData[_model].yVector, branchReference, tr->mxtips, states);
evaluatePartialGenericSpecial.c:      assert(!tr->saveMemory);
evaluatePartialGenericSpecial.c:      assert(tr->rateHetModel == CAT);
evaluatePartialGenericSpecial.c:       result = evaluatePartialGTRCAT_BINARY(index, ki, tr->td[0].count, tr->td[0].ti, tr->td[0].ti[0].qz[branchReference], 
evaluatePartialGenericSpecial.c:					    tr->partitionData[_model].wgt[index],
evaluatePartialGenericSpecial.c:					    tr->partitionData[_model].EIGN, 
evaluatePartialGenericSpecial.c:					    tr->partitionData[_model].EI, 
evaluatePartialGenericSpecial.c:					    tr->partitionData[_model].EV,
evaluatePartialGenericSpecial.c:					    tr->partitionData[_model].tipVector,
evaluatePartialGenericSpecial.c:					    tr->partitionData[_model].yVector, branchReference, tr->mxtips);
evaluatePartialGenericSpecial.c:      assert(tr->rateHetModel == CAT);  
evaluatePartialGenericSpecial.c:      result = evaluatePartialGTRCAT(index, ki, tr->td[0].count, tr->td[0].ti, tr->td[0].ti[0].qz[branchReference], 
evaluatePartialGenericSpecial.c:				     tr->partitionData[_model].wgt[index],
evaluatePartialGenericSpecial.c:				     tr->partitionData[_model].EIGN, 
evaluatePartialGenericSpecial.c:				     tr->partitionData[_model].EI, 
evaluatePartialGenericSpecial.c:				     tr->partitionData[_model].EV,
evaluatePartialGenericSpecial.c:				     tr->partitionData[_model].tipVector,
evaluatePartialGenericSpecial.c:				     tr->partitionData[_model].yVector, branchReference, tr->mxtips);
evaluatePartialGenericSpecial.c:      if(tr->rateHetModel == CAT)
evaluatePartialGenericSpecial.c:	result = evaluatePartialGTRCATPROT(index, ki, tr->td[0].count, tr->td[0].ti, tr->td[0].ti[0].qz[branchReference], 
evaluatePartialGenericSpecial.c:					   tr->partitionData[_model].wgt[index],
evaluatePartialGenericSpecial.c:					   tr->partitionData[_model].EIGN, 
evaluatePartialGenericSpecial.c:					   tr->partitionData[_model].EI, 
evaluatePartialGenericSpecial.c:					   tr->partitionData[_model].EV,
evaluatePartialGenericSpecial.c:					   tr->partitionData[_model].tipVector, 
evaluatePartialGenericSpecial.c:					   tr->partitionData[_model].yVector, branchReference, tr->mxtips);
evaluatePartialGenericSpecial.c:	result =  evaluatePartialGTRGAMMAPROT(index, tr->td[0].count, tr->td[0].ti, tr->td[0].ti[0].qz[branchReference], 
evaluatePartialGenericSpecial.c:					      tr->partitionData[_model].wgt[index],
evaluatePartialGenericSpecial.c:					      tr->partitionData[_model].EIGN, 
evaluatePartialGenericSpecial.c:					      tr->partitionData[_model].EI, 
evaluatePartialGenericSpecial.c:					      tr->partitionData[_model].EV,
evaluatePartialGenericSpecial.c:					      tr->partitionData[_model].tipVector, 
evaluatePartialGenericSpecial.c:					      tr->partitionData[_model].yVector, 
evaluatePartialGenericSpecial.c:					      tr->partitionData[_model].gammaRates,
evaluatePartialGenericSpecial.c:					      branchReference, tr->mxtips);
makenewzGenericSpecial.c:    rateHet = (int)discreteRateCategories(tr->rateHetModel),
makenewzGenericSpecial.c:    states = tr->partitionData[model].states,
makenewzGenericSpecial.c:  pNumber = tr->td[0].ti[0].pNumber;
makenewzGenericSpecial.c:  qNumber = tr->td[0].ti[0].qNumber;
makenewzGenericSpecial.c:  if(isTip(pNumber, tr->mxtips) || isTip(qNumber, tr->mxtips))
makenewzGenericSpecial.c:      if(!( isTip(pNumber, tr->mxtips) && isTip(qNumber, tr->mxtips)) )
makenewzGenericSpecial.c:	  if(isTip(qNumber, tr->mxtips))
makenewzGenericSpecial.c:	      if(isPomo(tr->partitionData[model].dataType))
makenewzGenericSpecial.c:		  *x1_start = tr->partitionData[model].xTipVector[qNumber];
makenewzGenericSpecial.c:		  *tipX1 = tr->partitionData[model].yVector[qNumber] + offset;
makenewzGenericSpecial.c:	      *x2_start = tr->partitionData[model].xVector[pNumber - tr->mxtips - 1] + x_offset;
makenewzGenericSpecial.c:	      if(tr->saveMemory)
makenewzGenericSpecial.c:		  *x2_gap = &(tr->partitionData[model].gapVector[pNumber * tr->partitionData[model].gapVectorLength]);
makenewzGenericSpecial.c:		  *x2_gapColumn   = &tr->partitionData[model].gapColumn[(pNumber - tr->mxtips - 1) * states * rateHet];  
makenewzGenericSpecial.c:	      if(isPomo(tr->partitionData[model].dataType))
makenewzGenericSpecial.c:		  *x1_start = tr->partitionData[model].xTipVector[pNumber];
makenewzGenericSpecial.c:		  *tipX1 = tr->partitionData[model].yVector[pNumber] + offset;
makenewzGenericSpecial.c:	      *x2_start = tr->partitionData[model].xVector[qNumber - tr->mxtips - 1] + x_offset;
makenewzGenericSpecial.c:	      if(tr->saveMemory)
makenewzGenericSpecial.c:		  *x2_gap = &(tr->partitionData[model].gapVector[qNumber * tr->partitionData[model].gapVectorLength]);
makenewzGenericSpecial.c:		  *x2_gapColumn   = &tr->partitionData[model].gapColumn[(qNumber - tr->mxtips - 1) * states * rateHet];
makenewzGenericSpecial.c:	  if(isPomo(tr->partitionData[model].dataType))
makenewzGenericSpecial.c:	      *x1_start = tr->partitionData[model].xTipVector[pNumber];
makenewzGenericSpecial.c:	      *x2_start = tr->partitionData[model].xTipVector[qNumber];
makenewzGenericSpecial.c:	      *tipX1 = tr->partitionData[model].yVector[pNumber] + offset;
makenewzGenericSpecial.c:	      *tipX2 = tr->partitionData[model].yVector[qNumber] + offset;
makenewzGenericSpecial.c:      *x1_start = tr->partitionData[model].xVector[pNumber - tr->mxtips - 1] + x_offset;
makenewzGenericSpecial.c:      *x2_start = tr->partitionData[model].xVector[qNumber - tr->mxtips - 1] + x_offset;
makenewzGenericSpecial.c:      if(tr->saveMemory)
makenewzGenericSpecial.c:	  *x1_gap = &(tr->partitionData[model].gapVector[pNumber * tr->partitionData[model].gapVectorLength]);
makenewzGenericSpecial.c:	  *x1_gapColumn   = &tr->partitionData[model].gapColumn[(pNumber - tr->mxtips - 1) * states * rateHet]; 
makenewzGenericSpecial.c:	  *x2_gap = &(tr->partitionData[model].gapVector[qNumber * tr->partitionData[model].gapVectorLength]);
makenewzGenericSpecial.c:	  *x2_gapColumn   = &tr->partitionData[model].gapColumn[(qNumber - tr->mxtips - 1) * states * rateHet]; 
makenewzGenericSpecial.c:    maxModel = tr->maxModelsPerThread;
makenewzGenericSpecial.c:    maxModel = tr->NumberOfModels;
makenewzGenericSpecial.c:	pAss = tr->threadPartAssigns[tid * tr->maxModelsPerThread + m];
makenewzGenericSpecial.c:      width  = (size_t)tr->partitionData[model].width;
makenewzGenericSpecial.c:      if(tr->td[0].executeModel[model] && width > 0)
makenewzGenericSpecial.c:	    rateHet = (int)discreteRateCategories(tr->rateHetModel),
makenewzGenericSpecial.c:	    states = tr->partitionData[model].states,
makenewzGenericSpecial.c:	    *sumBuffer = tr->partitionData[model].sumBuffer + x_offset;
makenewzGenericSpecial.c:	  assert(!tr->saveMemory);
makenewzGenericSpecial.c:	  if(tr->rateHetModel == CAT)
makenewzGenericSpecial.c:	    sumCAT_FLEX(tipCase, sumBuffer, x1_start, x2_start, tr->partitionData[model].tipVector, tipX1, tipX2,
makenewzGenericSpecial.c:	    sumGAMMA_FLEX(tipCase, sumBuffer, x1_start, x2_start, tr->partitionData[model].tipVector, tipX1, tipX2,
makenewzGenericSpecial.c:	      assert(!tr->saveMemory);
makenewzGenericSpecial.c:	      if(tr->rateHetModel == CAT)
makenewzGenericSpecial.c:		sumCAT_BINARY(tipCase, sumBuffer, x1_start, x2_start, tr->partitionData[model].tipVector,
makenewzGenericSpecial.c:		sumGAMMA_BINARY(tipCase, sumBuffer, x1_start, x2_start, tr->partitionData[model].tipVector,
makenewzGenericSpecial.c:	      if(tr->rateHetModel == CAT)
makenewzGenericSpecial.c:		  if(tr->saveMemory)
makenewzGenericSpecial.c:		    sumCAT_SAVE(tipCase, sumBuffer, x1_start, x2_start, tr->partitionData[model].tipVector, tipX1, tipX2,
makenewzGenericSpecial.c:			sumCAT(tipCase, sumBuffer, x1_start, x2_start, tr->partitionData[model].tipVector, tipX1, tipX2,
makenewzGenericSpecial.c:		  if(tr->saveMemory)
makenewzGenericSpecial.c:			  sumGAMMA_GAPPED_SAVE(tipCase, sumBuffer, x1_start, x2_start, tr->partitionData[model].tipVector, tipX1, tipX2,
makenewzGenericSpecial.c:             sumGAMMA_MIC(tipCase, sumBuffer, x1_start, x2_start, tr->partitionData[model].mic_tipVector, tipX1, tipX2,
makenewzGenericSpecial.c:			  sumGAMMA(tipCase, sumBuffer, x1_start, x2_start, tr->partitionData[model].tipVector, tipX1, tipX2,
makenewzGenericSpecial.c:	      if(tr->rateHetModel == CAT)
makenewzGenericSpecial.c:		  if(tr->saveMemory)
makenewzGenericSpecial.c:			  sumGTRCATPROT_SAVE(tipCase, sumBuffer, x1_start, x2_start, tr->partitionData[model].tipVector,
makenewzGenericSpecial.c:			  sumGTRCATPROT(tipCase, sumBuffer, x1_start, x2_start, tr->partitionData[model].tipVector,
makenewzGenericSpecial.c:		  if(tr->saveMemory)
makenewzGenericSpecial.c:		    sumGAMMAPROT_GAPPED_SAVE(tipCase, sumBuffer, x1_start, x2_start, tr->partitionData[model].tipVector, tipX1, tipX2,
makenewzGenericSpecial.c:		      if(tr->partitionData[model].protModels == LG4M || tr->partitionData[model].protModels == LG4X)		      			   		
makenewzGenericSpecial.c:			sumGAMMAPROT_LG4_MIC(tipCase, sumBuffer, x1_start, x2_start, tr->partitionData[model].mic_tipVector, tipX1, tipX2,
makenewzGenericSpecial.c:		      sumGAMMAPROT_LG4(tipCase,  sumBuffer, x1_start, x2_start, tr->partitionData[model].tipVector_LG4,
makenewzGenericSpecial.c:            sumGAMMAPROT_MIC(tipCase, sumBuffer, x1_start, x2_start, tr->partitionData[model].mic_tipVector, tipX1, tipX2,
makenewzGenericSpecial.c:		      sumGAMMAPROT(tipCase, sumBuffer, x1_start, x2_start, tr->partitionData[model].tipVector,
makenewzGenericSpecial.c:	      assert(!tr->saveMemory);
makenewzGenericSpecial.c:	      sumGAMMA_NSTATE(tipCase, sumBuffer, x1_start, x2_start, tr->partitionData[model].tipVector,
makenewzGenericSpecial.c:	      assert(!tr->saveMemory);
makenewzGenericSpecial.c:	      sumGAMMA_NSTATE(tipCase, sumBuffer, x1_start, x2_start, tr->partitionData[model].tipVector,
makenewzGenericSpecial.c:   in tr->coreLZ[model] Note that in the parallel case coreLZ must always be broadcasted together with the 
makenewzGenericSpecial.c:      nModels = (tr->numBranches > 1) ? tr->NumberOfModels : 1,
makenewzGenericSpecial.c:	tr->partitionData[p].reductionBuffer[tid] = 0.;
makenewzGenericSpecial.c:	tr->partitionData[p].reductionBuffer2[tid] = 0.;
makenewzGenericSpecial.c:    maxModel = tr->maxModelsPerThread;
makenewzGenericSpecial.c:    maxModel = tr->NumberOfModels;
makenewzGenericSpecial.c:	Assign* pAss = tr->threadPartAssigns[tid * tr->maxModelsPerThread + m];
makenewzGenericSpecial.c:	width  = (size_t)tr->partitionData[model].width;
makenewzGenericSpecial.c:	if(tr->numBranches > 1)
makenewzGenericSpecial.c:	    lz = tr->td[0].parameterValues[model];
makenewzGenericSpecial.c:	    lz = tr->td[0].parameterValues[0];
makenewzGenericSpecial.c:	d1acc = &tr->partitionData[branchIndex].reductionBuffer[tid];
makenewzGenericSpecial.c:	d2acc = &tr->partitionData[branchIndex].reductionBuffer2[tid];
makenewzGenericSpecial.c:       if(tr->td[0].executeModel[model] && width > 0)
makenewzGenericSpecial.c:	    rateHet = (int)discreteRateCategories(tr->rateHetModel),
makenewzGenericSpecial.c:	    states = tr->partitionData[model].states,
makenewzGenericSpecial.c:	    *wgt = tr->partitionData[model].wgt + offset,
makenewzGenericSpecial.c:	    *rateCategory = tr->partitionData[model].rateCategory + offset;
makenewzGenericSpecial.c:	    *weights         = tr->partitionData[model].weights,
makenewzGenericSpecial.c:	    *sumBuffer = tr->partitionData[model].sumBuffer + x_offset;
makenewzGenericSpecial.c:	    if(tr->rateHetModel == CAT)
makenewzGenericSpecial.c:	      coreCAT_FLEX(width, tr->partitionData[model].numberOfCategories, sumBuffer,
makenewzGenericSpecial.c:			   tr->partitionData[model].perSiteRates, tr->partitionData[model].EIGN, rateCategory, lz, states);
makenewzGenericSpecial.c:			     &dlnLdlz, &d2lnLdlz2, tr->partitionData[model].EIGN, tr->partitionData[model].gammaRates, lz,
makenewzGenericSpecial.c:		assert(!tr->saveMemory);
makenewzGenericSpecial.c:		if(tr->rateHetModel == CAT)
makenewzGenericSpecial.c:		  coreGTRCAT_BINARY(width, tr->partitionData[model].numberOfCategories, sumBuffer,
makenewzGenericSpecial.c:				    tr->partitionData[model].perSiteRates, tr->partitionData[model].EIGN,  rateCategory,
makenewzGenericSpecial.c:				       tr->partitionData[model].EIGN, 
makenewzGenericSpecial.c:				       tr->partitionData[model].gammaRates, lz, wgt);
makenewzGenericSpecial.c:		if(tr->rateHetModel == CAT)
makenewzGenericSpecial.c:			    coreGTRCAT(width, tr->partitionData[model].numberOfCategories, sumBuffer,
makenewzGenericSpecial.c:					    tr->partitionData[model].perSiteRates, tr->partitionData[model].EIGN,  rateCategory, lz);
makenewzGenericSpecial.c:			     &dlnLdlz, &d2lnLdlz2, tr->partitionData[model].EIGN, tr->partitionData[model].gammaRates, lz, wgt);
makenewzGenericSpecial.c:					    &dlnLdlz, &d2lnLdlz2, tr->partitionData[model].EIGN, tr->partitionData[model].gammaRates, lz, wgt);
makenewzGenericSpecial.c:		if(tr->rateHetModel == CAT)
makenewzGenericSpecial.c:			    coreGTRCATPROT(tr->partitionData[model].EIGN, lz, tr->partitionData[model].numberOfCategories,  tr->partitionData[model].perSiteRates,
makenewzGenericSpecial.c:		  if(tr->partitionData[model].protModels == LG4M || tr->partitionData[model].protModels == LG4X)
makenewzGenericSpecial.c:					     &dlnLdlz, &d2lnLdlz2, tr->partitionData[model].EIGN_LG4, tr->partitionData[model].gammaRates,
makenewzGenericSpecial.c:		  coreGTRGAMMAPROT_LG4(tr->partitionData[model].gammaRates, tr->partitionData[model].EIGN_LG4,
makenewzGenericSpecial.c:					   &dlnLdlz, &d2lnLdlz2, tr->partitionData[model].EIGN, tr->partitionData[model].gammaRates, lz, wgt);
makenewzGenericSpecial.c:		  coreGTRGAMMAPROT(tr->partitionData[model].gammaRates, tr->partitionData[model].EIGN,
makenewzGenericSpecial.c:		assert(!tr->saveMemory);
makenewzGenericSpecial.c:		coreGTRGAMMA_NSTATE(tr->partitionData[model].gammaRates, tr->partitionData[model].EIGN,
makenewzGenericSpecial.c:		assert(!tr->saveMemory);
makenewzGenericSpecial.c:		coreGTRGAMMA_NSTATE(tr->partitionData[model].gammaRates, tr->partitionData[model].EIGN,
makenewzGenericSpecial.c:	    if(width == 0 && (tr->numBranches > 1))
makenewzGenericSpecial.c:	    if(width > 0 && (tr->numBranches > 1))
makenewzGenericSpecial.c:		assert(tr->td[0].executeModel[model] == FALSE);
makenewzGenericSpecial.c:  int nModels = (tr->numBranches > 1) ? tr->NumberOfModels : 1;
makenewzGenericSpecial.c:    for(tid = 0; tid < tr->nThreads; tid++)
makenewzGenericSpecial.c:      _dlnLdlz[model] += tr->partitionData[model].reductionBuffer[tid];
makenewzGenericSpecial.c:      _d2lnLdlz2[model] += tr->partitionData[model].reductionBuffer2[tid];
makenewzGenericSpecial.c:  for(i = 0; i < tr->numBranches; i++)
makenewzGenericSpecial.c:      tr->curvatOK[i]       = TRUE;
makenewzGenericSpecial.c:      for(i = 0; i < tr->numBranches; i++)
makenewzGenericSpecial.c:	  if(outerConverged[i] == FALSE && tr->curvatOK[i] == TRUE)
makenewzGenericSpecial.c:	      tr->curvatOK[i] = FALSE;
makenewzGenericSpecial.c:      for(i = 0; i < tr->numBranches; i++)
makenewzGenericSpecial.c:	  if(outerConverged[i] == FALSE && tr->curvatOK[i] == FALSE)
makenewzGenericSpecial.c:	      tr->coreLZ[i] = lz;
makenewzGenericSpecial.c:      if(tr->numBranches > 1)
makenewzGenericSpecial.c:	  assert(tr->numBranches == tr->NumberOfModels);
makenewzGenericSpecial.c:	  for(model = 0; model < tr->NumberOfModels; model++)
makenewzGenericSpecial.c:	      if(tr->executeModel[model])
makenewzGenericSpecial.c:		tr->executeModel[model] = !tr->curvatOK[model];
makenewzGenericSpecial.c:	  for(model = 0; model < tr->NumberOfModels; model++)
makenewzGenericSpecial.c:	    tr->executeModel[model] = !tr->curvatOK[0];
makenewzGenericSpecial.c:      storeValuesInTraversalDescriptor(tr, &(tr->coreLZ[0]));
makenewzGenericSpecial.c:	  *send = (double *)malloc(sizeof(double) * tr->numBranches * 2),
makenewzGenericSpecial.c:	  *recv = (double *)malloc(sizeof(double) * tr->numBranches * 2);		
makenewzGenericSpecial.c:	memcpy(&send[0],                dlnLdlz,   sizeof(double) * tr->numBranches);
makenewzGenericSpecial.c:	memcpy(&send[tr->numBranches],  d2lnLdlz2, sizeof(double) * tr->numBranches);
makenewzGenericSpecial.c:	MPI_Allreduce(send, recv, tr->numBranches * 2, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);	    	    
makenewzGenericSpecial.c:	MPI_Reduce(send, recv, tr->numBranches * 2, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD);
makenewzGenericSpecial.c:	MPI_Bcast(recv,        tr->numBranches * 2, MPI_DOUBLE, 0, MPI_COMM_WORLD);
makenewzGenericSpecial.c:	memcpy(dlnLdlz,   &recv[0],               sizeof(double) * tr->numBranches);
makenewzGenericSpecial.c:	memcpy(d2lnLdlz2, &recv[tr->numBranches], sizeof(double) * tr->numBranches);
makenewzGenericSpecial.c:      for(i = 0; i < tr->numBranches; i++)
makenewzGenericSpecial.c:	  if(outerConverged[i] == FALSE && tr->curvatOK[i] == FALSE)
makenewzGenericSpecial.c:		tr->curvatOK[i] = TRUE;
makenewzGenericSpecial.c:      for(i = 0; i < tr->numBranches; i++)
makenewzGenericSpecial.c:	  if(tr->curvatOK[i] == TRUE && outerConverged[i] == FALSE)
makenewzGenericSpecial.c:      for(i = 0; i < tr->numBranches; i++)
makenewzGenericSpecial.c:  for(model = 0; model < tr->NumberOfModels; model++)
makenewzGenericSpecial.c:    tr->executeModel[model] = TRUE;
makenewzGenericSpecial.c:  for(i = 0; i < tr->numBranches; i++)    
makenewzGenericSpecial.c:  tr->td[0].ti[0].pNumber = p->number;
makenewzGenericSpecial.c:  tr->td[0].ti[0].qNumber = q->number;
makenewzGenericSpecial.c:  for(i = 0; i < tr->numBranches; i++)
makenewzGenericSpecial.c:      tr->td[0].ti[0].qz[i] =  z0[i];
makenewzGenericSpecial.c:	  if(tr->partitionConverged[i])
makenewzGenericSpecial.c:	    tr->executeModel[i] = FALSE;
makenewzGenericSpecial.c:	    tr->executeModel[i] = TRUE;
makenewzGenericSpecial.c:	assert(tr->executeModel[i]);
makenewzGenericSpecial.c:  tr->td[0].count = 1;
makenewzGenericSpecial.c:    computeTraversalInfo(p, &(tr->td[0].ti[0]), &(tr->td[0].count), tr->mxtips, tr->numBranches, TRUE);
makenewzGenericSpecial.c:    computeTraversalInfo(q, &(tr->td[0].ti[0]), &(tr->td[0].count), tr->mxtips, tr->numBranches, TRUE); 
makenewzGenericSpecial.c:  for(i = 0; i < tr->numBranches; i++)
makenewzGenericSpecial.c:      tr->executeModel[i] = TRUE;
models.c:  if(tr->NumberOfModels == 1)    
models.c:      assert(tr->fracchanges[0] != -1.0);
models.c:      tr->fracchange = tr->fracchanges[0];      
models.c:      tr->fracchanges[0] = -1.0;
models.c:      assert(tr->NumberOfModels > 1);
models.c:      tr->fracchange = 0.0;	                     
models.c:      for(model = 0; model < tr->NumberOfModels; model++)                   
models.c:	tr->fracchange +=  tr->partitionContributions[model] * tr->fracchanges[model];	
models.c:  tr->rawFracchange = tr->fracchange;
models.c:  memcpy(tr->rawFracchanges, tr->fracchanges, sizeof(double) * tr->NumberOfModels);
models.c:    states = (size_t)(tr->partitionData[model].states),
models.c:    width =  tr->partitionData[model].width;
models.c:    *EV = tr->partitionData[model].EV;
models.c:  for(i = 1; i <= (size_t)tr->mxtips; i++)
models.c:	*xv = tr->partitionData[model].xTipVector[i],
models.c:	*pv = tr->partitionData[model].xTipCLV[i];	  
models.c:    *fracchanges      = tr->fracchanges,    
models.c:    *ext_EIGN         = tr->partitionData[model].EIGN,
models.c:    *EV               = tr->partitionData[model].EV,
models.c:    *EI               = tr->partitionData[model].EI,
models.c:    *frequencies      = tr->partitionData[model].frequencies,
models.c:    *ext_initialRates = tr->partitionData[model].substRates,
models.c:    *tipVector        = tr->partitionData[model].tipVector;
models.c:    states = tr->partitionData[model].states;
models.c:  switch(tr->partitionData[model].dataType)
models.c:		  getBitVector(tr->partitionData[model].dataType), 
models.c:		  getUndetermined(tr->partitionData[model].dataType) + 1, 
models.c:		  model, tr->partitionData[model].dataType, tr);
models.c:     if(tr->partitionData[model].protModels != GTR)           
models.c:	 if(tr->partitionData[model].protModels == LG4M || tr->partitionData[model].protModels == LG4X)
models.c:		 initProtMat(f, tr->partitionData[model].protModels, &(tr->partitionData[model].substRates_LG4[i][0]), i);
models.c:		 if(!tr->partitionData[model].protFreqs && !tr->partitionData[model].optimizeBaseFrequencies)
models.c:		   memcpy(tr->partitionData[model].frequencies_LG4[i], f, 20 * sizeof(double));
models.c:		 //   tr->partitionData[model].frequencies_LG4[i][l] = f[l];
models.c:		   memcpy(tr->partitionData[model].frequencies_LG4[i], frequencies, 20 * sizeof(double));
models.c:	     if(tr->partitionData[model].protModels == AUTO)
models.c:	       initProtMat(f, tr->partitionData[model].autoProtModels, ext_initialRates, 0);
models.c:	       initProtMat(f, tr->partitionData[model].protModels, ext_initialRates, 0); 		   
models.c:	     /*if(adef->protEmpiricalFreqs && tr->NumberOfModels == 1)
models.c:	       assert(tr->partitionData[model].protFreqs);*/
models.c:	     if(tr->partitionData[model].protModels == AUTO)
models.c:		 if(tr->partitionData[model].protFreqs)
models.c:		   memcpy(frequencies, tr->partitionData[model].empiricalFrequencies, 20 * sizeof(double));		 
models.c:		 if(!tr->partitionData[model].optimizeBaseFrequencies)
models.c:		     if(!tr->partitionData[model].protFreqs)	       	  
models.c:			 memcpy(frequencies, tr->partitionData[model].empiricalFrequencies, 20 * sizeof(double));
models.c:			   frequencies[l] = tr->partitionData[model].empiricalFrequencies[l];			 */
models.c:     if(tr->partitionData[model].protModels == LG4M || tr->partitionData[model].protModels == LG4X)
models.c:	     fracchanges_LG4[i]  = (double *)malloc(tr->NumberOfModels * sizeof(double));
models.c:			 tr->partitionData[model].EIGN_LG4[i],  tr->partitionData[model].EV_LG4[i],  
models.c:			 tr->partitionData[model].EI_LG4[i], tr->partitionData[model].frequencies_LG4[i], 
models.c:			 tr->partitionData[model].substRates_LG4[i],
models.c:			 tr->partitionData[model].tipVector_LG4[i], 
models.c:			 model, tr->partitionData[model].dataType, tr);   
models.c:	 tr->fracchanges[model] = acc / 4;
models.c:		   model, tr->partitionData[model].dataType, tr);                   
models.c:  if(tr->partitionData[model].protModels == LG4M || tr->partitionData[model].protModels == LG4X)
models.c:    updateModel_LG4_MIC(&tr->partitionData[model]);
models.c:    updateModel_MIC(&tr->partitionData[model]);
models.c:  for(model = 0; model < tr->NumberOfModels; model++)
models.c:	states = tr->partitionData[model].states,
models.c:      switch(tr->partitionData[model].dataType)
models.c:	  setRates(tr->partitionData[model].pomoRates, 6);
models.c:	  setRates(tr->partitionData[model].substRates, rates);
models.c:	  switch(tr->multiStateModel)
models.c:		    tr->partitionData[model].substRates[i++] = (double)(k - j);			
models.c:		tr->partitionData[model].substRates[i] = 1.0;
models.c:	      setRates(tr->partitionData[model].substRates, rates);
models.c:	  if(tr->partitionData[model].protModels == GTR)	      
models.c:	    putWAG(tr->partitionData[model].substRates);
models.c:      if(tr->partitionData[model].nonGTR)
models.c:	  assert(tr->partitionData[model].dataType == SECONDARY_DATA || 
models.c:		 tr->partitionData[model].dataType == SECONDARY_DATA_6 ||
models.c:		 tr->partitionData[model].dataType == SECONDARY_DATA_7);
models.c:	      if(tr->partitionData[model].symmetryVector[i] == -1)
models.c:		tr->partitionData[model].substRates[i] = 0.0;
models.c:		  if(tr->partitionData[model].symmetryVector[i] == tr->partitionData[model].symmetryVector[rates - 1])
models.c:		    tr->partitionData[model].substRates[i] = 1.0;
models.c:  for(model = 0; model < tr->NumberOfModels; model++)
models.c:      if(tr->partitionData[model].dataType == SECONDARY_DATA || 
models.c:	 tr->partitionData[model].dataType == SECONDARY_DATA_6 || 
models.c:	 tr->partitionData[model].dataType == SECONDARY_DATA_7)
models.c:	  switch(tr->secondaryStructureModel)
models.c:	      tr->partitionData[model].nonGTR = FALSE;
models.c:		setSymmetry(s, tr->partitionData[model].symmetryVector, 15, f, tr->partitionData[model].frequencyGrouping, 6);
models.c:		tr->partitionData[model].nonGTR = TRUE;
models.c:		setSymmetry(s, tr->partitionData[model].symmetryVector, 15, f, tr->partitionData[model].frequencyGrouping, 6);
models.c:		tr->partitionData[model].nonGTR = TRUE;
models.c:		setSymmetry(s, tr->partitionData[model].symmetryVector, 15, f, tr->partitionData[model].frequencyGrouping, 6);
models.c:		tr->partitionData[model].nonGTR = TRUE;
models.c:		setSymmetry(s, tr->partitionData[model].symmetryVector, 15, f, tr->partitionData[model].frequencyGrouping, 6);
models.c:		tr->partitionData[model].nonGTR = TRUE;
models.c:	      tr->partitionData[model].nonGTR = FALSE;
models.c:		setSymmetry(s, tr->partitionData[model].symmetryVector, 21, f, tr->partitionData[model].frequencyGrouping, 7);
models.c:		tr->partitionData[model].nonGTR = TRUE;
models.c:		setSymmetry(s, tr->partitionData[model].symmetryVector, 21, f, tr->partitionData[model].frequencyGrouping, 7);
models.c:		tr->partitionData[model].nonGTR = TRUE;
models.c:		setSymmetry(s, tr->partitionData[model].symmetryVector, 21, f, tr->partitionData[model].frequencyGrouping, 7);
models.c:		tr->partitionData[model].nonGTR = TRUE;
models.c:		setSymmetry(s, tr->partitionData[model].symmetryVector, 21, f, tr->partitionData[model].frequencyGrouping, 7);
models.c:		tr->partitionData[model].nonGTR = TRUE;
models.c:		setSymmetry(s, tr->partitionData[model].symmetryVector, 21, f, tr->partitionData[model].frequencyGrouping, 7);
models.c:		tr->partitionData[model].nonGTR = TRUE;
models.c:	      tr->partitionData[1].nonGTR = FALSE;
models.c:		setSymmetry(s, tr->partitionData[model].symmetryVector, 120, f, tr->partitionData[model].frequencyGrouping, 16);
models.c:		tr->partitionData[model].nonGTR = TRUE;
models.c:		setSymmetry(s, tr->partitionData[model].symmetryVector, 120, f, tr->partitionData[model].frequencyGrouping, 16);
models.c:		tr->partitionData[model].nonGTR = TRUE;
models.c:  return tr->partitionData[model].pomoRates[index];
models.c:    *f = tr->partitionData[model].pomoFrequencies,
models.c:    n = tr->partitionData[model].pomoN; 
models.c:  tr->partitionData[model].pomoK = result;
models.c:    n = (double)tr->partitionData[model].pomoN,
models.c:    ratio =  tr->partitionData[model].pomoPhi / tr->partitionData[model].pomoK,
models.c:    *f = tr->partitionData[model].pomoFrequencies;
models.c:      tr->partitionData[model].frequencies[l] = f[l] * (1.0 - tr->partitionData[model].pomoPhi);  
models.c:      sum += tr->partitionData[model].frequencies[l];
models.c:      for(k = 1; k < tr->partitionData[model].pomoN; k++)
models.c:	      (double)(k * (tr->partitionData[model].pomoN - k))); 
models.c:	  tr->partitionData[model].frequencies[l++] =  v;
models.c:  assert(l == tr->partitionData[model].states);
models.c:    states = (int)tr->partitionData[model].states, 
models.c:    stride = (int)tr->partitionData[model].pomoN - 1;
models.c:    nSquare = (double)(tr->partitionData[model].pomoN * tr->partitionData[model].pomoN);
models.c:      m[i][j] = tr->partitionData[model].pomoRates[l++];
models.c:      tr->partitionData[model].substRates[l++] = m[i][j];
models.c:  for(model = 0; model < (size_t)tr->NumberOfModels; model++)
models.c:	numFreqs = (isPomo(tr->partitionData[model].dataType))? 4 : tr->partitionData[model].states;
models.c:      if(tr->partitionData[model].optimizeBaseFrequencies)
models.c:	      if(isPomo(tr->partitionData[model].dataType))
models.c:		tr->partitionData[model].pomoFrequencies[l] = f;
models.c:	      tr->partitionData[model].frequencies[l] = f;
models.c:	      tr->partitionData[model].empiricalFrequencies[l] = f;
models.c:	  memcpy(tr->partitionData[model].empiricalFrequencies, tr->partitionData[model].frequencies, sizeof(double) * numFreqs);
models.c:	  if(isPomo(tr->partitionData[model].dataType))
models.c:	    memcpy(tr->partitionData[model].pomoFrequencies, tr->partitionData[model].frequencies,  sizeof(double) * numFreqs);
models.c:  for(model = 0; model < (size_t)tr->NumberOfModels; model++)
models.c:	dataType = tr->partitionData[model].dataType;
models.c:	  tr->partitionData[model].pomoPhi = 0.5; 
models.c:	      tr->partitionData[model].pomoN = 3;
models.c:	      tr->partitionData[model].pomoN = 11;
models.c:  tr->numberOfInvariableColumns = 0;
models.c:  tr->weightOfInvariableColumns = 0;	       
models.c:  if(tr->rateHetModel == CAT)
models.c:      for(model = 0; model < tr->NumberOfModels; model++)
models.c:	  tr->partitionData[model].numberOfCategories = 1;           
models.c:	  tr->partitionData[model].perSiteRates[0] = 1.0; 
models.c:	  for(i = 0; i < tr->partitionData[model].width; ++i)
models.c:	      tr->partitionData[model].rateCategory[i] = 0; 
models.c:	      tr->partitionData[model].patrat[i] = 1.; 
models.c:  for(model = 0; model < tr->NumberOfModels; model++)
models.c:      tr->partitionData[model].alpha = 1.0;    
models.c:      if(tr->partitionData[model].protModels == AUTO)
models.c:	tr->partitionData[model].autoProtModels = WAG; /* initialize by WAG per default when AUTO is used */
models.c:      makeGammaCats(tr->partitionData[model].alpha, tr->partitionData[model].gammaRates, 4, tr->useMedian);     
models.c:      for(k = 0; k < tr->partitionData[model].states; k++)
models.c:	tr->partitionData[model].freqExponents[k] = 0.0;	
models.c:	  tr->partitionData[model].weights[k] = 0.25;
models.c:	  tr->partitionData[model].weightExponents[k] = 0.0;
models.c:  if(tr->NumberOfModels > 1)
models.c:      tr->fracchange = 0;
models.c:      for(model = 0; model < tr->NumberOfModels; model++)	
models.c:	tr->fracchange += tr->fracchanges[model];      
models.c:      tr->fracchange /= ((double)tr->NumberOfModels);
newviewGenericSpecial.c:    *ti   = tr->td[0].ti;
newviewGenericSpecial.c:  for(i = startIndex; i < tr->td[0].count; i++)
newviewGenericSpecial.c:      for(model = 0; model < tr->NumberOfModels; model++)
newviewGenericSpecial.c:	  if(!tr->td[0].executeModel[model] || tr->partitionData[model].width == 0)
newviewGenericSpecial.c:	    states = tr->partitionData[model].states;
newviewGenericSpecial.c:	    *left = tr->partitionData[model].left,
newviewGenericSpecial.c:	    *right = tr->partitionData[model].right;
newviewGenericSpecial.c:	  if(tr->rateHetModel == CAT)
newviewGenericSpecial.c:	      rateCategories = tr->partitionData[model].perSiteRates;
newviewGenericSpecial.c:	      categories = tr->partitionData[model].numberOfCategories;
newviewGenericSpecial.c:	      rateCategories = tr->partitionData[model].gammaRates;
newviewGenericSpecial.c:	  if(tr->numBranches > 1)
newviewGenericSpecial.c:	  switch (tr->partitionData[model].states)
newviewGenericSpecial.c:		makeP_DNA_MIC(qz, rz, rateCategories,   tr->partitionData[model].EI,
newviewGenericSpecial.c:			      tr->partitionData[model].EIGN, categories,
newviewGenericSpecial.c:			      left, right, tr->saveMemory, tr->maxCategories);
newviewGenericSpecial.c:		precomputeTips_DNA_MIC(tInfo->tipCase, tr->partitionData[model].tipVector,
newviewGenericSpecial.c:				       tr->partitionData[model].mic_umpLeft, tr->partitionData[model].mic_umpRight,
newviewGenericSpecial.c:		if(tr->partitionData[model].protModels == LG4M || tr->partitionData[model].protModels == LG4X)
newviewGenericSpecial.c:		    makeP_PROT_LG4_MIC(qz, rz, tr->partitionData[model].gammaRates,
newviewGenericSpecial.c:				       tr->partitionData[model].EI_LG4, tr->partitionData[model].EIGN_LG4,
newviewGenericSpecial.c:		    precomputeTips_PROT_LG4_MIC(tInfo->tipCase, tr->partitionData[model].tipVector_LG4,
newviewGenericSpecial.c:						tr->partitionData[model].mic_umpLeft, tr->partitionData[model].mic_umpRight,
newviewGenericSpecial.c:		    makeP_PROT_MIC(qz, rz, rateCategories, tr->partitionData[model].EI,
newviewGenericSpecial.c:				   tr->partitionData[model].EIGN, categories,
newviewGenericSpecial.c:				   left, right, tr->saveMemory, tr->maxCategories);
newviewGenericSpecial.c:		    precomputeTips_PROT_MIC(tInfo->tipCase, tr->partitionData[model].tipVector,
newviewGenericSpecial.c:					    tr->partitionData[model].mic_umpLeft, tr->partitionData[model].mic_umpRight,
newviewGenericSpecial.c:	  if(tr->partitionData[model].protModels == LG4M || tr->partitionData[model].protModels == LG4X)
newviewGenericSpecial.c:	    makeP_FlexLG4(qz, rz, tr->partitionData[model].gammaRates,
newviewGenericSpecial.c:			  tr->partitionData[model].EI_LG4,
newviewGenericSpecial.c:			  tr->partitionData[model].EIGN_LG4,
newviewGenericSpecial.c:	    makeP(qz, rz, rateCategories,   tr->partitionData[model].EI,
newviewGenericSpecial.c:		  tr->partitionData[model].EIGN, categories,
newviewGenericSpecial.c:		  left, right, tr->saveMemory, tr->maxCategories, states);
newviewGenericSpecial.c:	maxModel = tr->maxModelsPerThread;
newviewGenericSpecial.c:	maxModel = tr->NumberOfModels;
newviewGenericSpecial.c:	      pAss = tr->threadPartAssigns[tid * tr->maxModelsPerThread + m];
newviewGenericSpecial.c:		left  = tr->partitionData[model].left;
newviewGenericSpecial.c:		right = tr->partitionData[model].right;
newviewGenericSpecial.c:		globalScaler = tr->partitionData[model].threadGlobalScaler[tid];
newviewGenericSpecial.c:	    width  = (size_t)tr->partitionData[model].width;
newviewGenericSpecial.c:	    left  = tr->partitionData[model].left;
newviewGenericSpecial.c:	    right = tr->partitionData[model].right;
newviewGenericSpecial.c:	    globalScaler = tr->partitionData[model].globalScaler;
newviewGenericSpecial.c:	    if(tr->td[0].executeModel[model] && width > 0)
newviewGenericSpecial.c:		  *x3_start = (double*)NULL, //tr->partitionData[model].xVector[tInfo->pNumber - tr->mxtips - 1],
newviewGenericSpecial.c:		  *wgt = tr->partitionData[model].wgt + offset,
newviewGenericSpecial.c:		  *rateCategory = tr->partitionData[model].rateCategory + offset;
newviewGenericSpecial.c:		  rateHet = discreteRateCategories(tr->rateHetModel),
newviewGenericSpecial.c:		  states = (size_t)tr->partitionData[model].states,	
newviewGenericSpecial.c:		     So tr->partitionData[model].xSpaceVector[i] provides the length of the allocated conditional array of partition model 
newviewGenericSpecial.c:		  availableLength = tr->partitionData[model].xSpaceVector[(tInfo->pNumber - tr->mxtips - 1)],
newviewGenericSpecial.c:		x3_start = tr->partitionData[model].xVector[tInfo->pNumber - tr->mxtips - 1] + x_offset;
newviewGenericSpecial.c:		if(tr->saveMemory)
newviewGenericSpecial.c:		    gapOffset = states * (size_t)getUndetermined(tr->partitionData[model].dataType);
newviewGenericSpecial.c:		    x1_gap = &(tr->partitionData[model].gapVector[tInfo->qNumber * tr->partitionData[model].gapVectorLength]);
newviewGenericSpecial.c:		    x2_gap = &(tr->partitionData[model].gapVector[tInfo->rNumber * tr->partitionData[model].gapVectorLength]);
newviewGenericSpecial.c:		    x3_gap = &(tr->partitionData[model].gapVector[tInfo->pNumber * tr->partitionData[model].gapVectorLength]);		      		  
newviewGenericSpecial.c:		    for(j = 0; j < (size_t)tr->partitionData[model].gapVectorLength; j++)
newviewGenericSpecial.c:			setBits += (size_t)(precomputed16_bitcount(x3_gap[j], tr->bits_in_16bits));		      
newviewGenericSpecial.c:		    tr->partitionData[model].xVector[tInfo->pNumber - tr->mxtips - 1] = x3_start;
newviewGenericSpecial.c:		    tr->partitionData[model].xSpaceVector[(tInfo->pNumber - tr->mxtips - 1)] = requiredLength;
newviewGenericSpecial.c:		    if(isPomo(tr->partitionData[model].dataType))
newviewGenericSpecial.c:			x1_start = tr->partitionData[model].xTipVector[tInfo->qNumber];						
newviewGenericSpecial.c:			x2_start = tr->partitionData[model].xTipVector[tInfo->rNumber];
newviewGenericSpecial.c:			tipX1    = tr->partitionData[model].yVector[tInfo->qNumber] + offset;
newviewGenericSpecial.c:			tipX2    = tr->partitionData[model].yVector[tInfo->rNumber] + offset;
newviewGenericSpecial.c:		    if(tr->saveMemory)
newviewGenericSpecial.c:			x1_gapColumn   = &(tr->partitionData[model].tipVector[gapOffset]);
newviewGenericSpecial.c:			x2_gapColumn   = &(tr->partitionData[model].tipVector[gapOffset]);		    
newviewGenericSpecial.c:			x3_gapColumn   = &tr->partitionData[model].gapColumn[(tInfo->pNumber - tr->mxtips - 1) * states * rateHet];		    
newviewGenericSpecial.c:		    if(isPomo(tr->partitionData[model].dataType))
newviewGenericSpecial.c:			x1_start = tr->partitionData[model].xTipVector[tInfo->qNumber];
newviewGenericSpecial.c:			tipX1    =  tr->partitionData[model].yVector[tInfo->qNumber] + offset;
newviewGenericSpecial.c:		    x2_start = tr->partitionData[model].xVector[tInfo->rNumber - tr->mxtips - 1] + x_offset;
newviewGenericSpecial.c:		    if(tr->saveMemory)
newviewGenericSpecial.c:			x1_gapColumn   = &(tr->partitionData[model].tipVector[gapOffset]);	     
newviewGenericSpecial.c:			x2_gapColumn   = &tr->partitionData[model].gapColumn[(tInfo->rNumber - tr->mxtips - 1) * states * rateHet];
newviewGenericSpecial.c:			x3_gapColumn   = &tr->partitionData[model].gapColumn[(tInfo->pNumber - tr->mxtips - 1) * states * rateHet];
newviewGenericSpecial.c:		    if(isPomo(tr->partitionData[model].dataType))	 		 
newviewGenericSpecial.c:		    x1_start       = tr->partitionData[model].xVector[tInfo->qNumber - tr->mxtips - 1] + x_offset;
newviewGenericSpecial.c:		    x2_start       = tr->partitionData[model].xVector[tInfo->rNumber - tr->mxtips - 1] + x_offset;
newviewGenericSpecial.c:		    if(tr->saveMemory)
newviewGenericSpecial.c:			x1_gapColumn   = &tr->partitionData[model].gapColumn[(tInfo->qNumber - tr->mxtips - 1) * states * rateHet];
newviewGenericSpecial.c:			x2_gapColumn   = &tr->partitionData[model].gapColumn[(tInfo->rNumber - tr->mxtips - 1) * states * rateHet];
newviewGenericSpecial.c:			x3_gapColumn   = &tr->partitionData[model].gapColumn[(tInfo->pNumber - tr->mxtips - 1) * states * rateHet];
newviewGenericSpecial.c:	      assert(!tr->saveMemory);
newviewGenericSpecial.c:	      if(tr->rateHetModel == CAT)
newviewGenericSpecial.c:		newviewCAT_FLEX(tInfo->tipCase,  tr->partitionData[model].EV, rateCategory,
newviewGenericSpecial.c:				x1_start, x2_start, x3_start, tr->partitionData[model].tipVector,
newviewGenericSpecial.c:				  x1_start, x2_start, x3_start, tr->partitionData[model].EV, tr->partitionData[model].tipVector,
newviewGenericSpecial.c:				  width, left, right, wgt, &scalerIncrement, states, getUndetermined(tr->partitionData[model].dataType) + 1);
newviewGenericSpecial.c:		  assert(!tr->saveMemory);
newviewGenericSpecial.c:		  if(tr->rateHetModel == CAT)
newviewGenericSpecial.c:		    newviewGTRCAT_BINARY(tInfo->tipCase,  tr->partitionData[model].EV,  rateCategory,
newviewGenericSpecial.c:					 x1_start,  x2_start,  x3_start, tr->partitionData[model].tipVector,
newviewGenericSpecial.c:					   tr->partitionData[model].EV, tr->partitionData[model].tipVector,
newviewGenericSpecial.c:		  if(tr->rateHetModel == CAT)
newviewGenericSpecial.c:		      if(tr->saveMemory)
newviewGenericSpecial.c:			newviewGTRCAT_AVX_GAPPED_SAVE(tInfo->tipCase,  tr->partitionData[model].EV, rateCategory,
newviewGenericSpecial.c:						      x1_start, x2_start, x3_start, tr->partitionData[model].tipVector,
newviewGenericSpecial.c:						      x1_gapColumn, x2_gapColumn, x3_gapColumn, tr->maxCategories);
newviewGenericSpecial.c:			newviewGTRCAT_SAVE(tInfo->tipCase,  tr->partitionData[model].EV, rateCategory,
newviewGenericSpecial.c:					   x1_start, x2_start, x3_start, tr->partitionData[model].tipVector,
newviewGenericSpecial.c:					   x1_gapColumn, x2_gapColumn, x3_gapColumn, tr->maxCategories);
newviewGenericSpecial.c:			newviewGTRCAT_AVX(tInfo->tipCase,  tr->partitionData[model].EV, rateCategory,
newviewGenericSpecial.c:					  x1_start, x2_start, x3_start, tr->partitionData[model].tipVector,
newviewGenericSpecial.c:			newviewGTRCAT(tInfo->tipCase,  tr->partitionData[model].EV, rateCategory,
newviewGenericSpecial.c:				      x1_start, x2_start, x3_start, tr->partitionData[model].tipVector,
newviewGenericSpecial.c:		       if(tr->saveMemory)
newviewGenericSpecial.c:							 x1_start, x2_start, x3_start, tr->partitionData[model].EV, tr->partitionData[model].tipVector, (int*)NULL,
newviewGenericSpecial.c:						   x1_start, x2_start, x3_start, tr->partitionData[model].EV, tr->partitionData[model].tipVector,
newviewGenericSpecial.c:				  x1_start, x2_start, x3_start, tr->partitionData[model].mic_EV, tr->partitionData[model].tipVector,
newviewGenericSpecial.c:				  tr->partitionData[model].mic_umpLeft, tr->partitionData[model].mic_umpRight);
newviewGenericSpecial.c:					     x1_start, x2_start, x3_start, tr->partitionData[model].EV, tr->partitionData[model].tipVector,
newviewGenericSpecial.c:					 x1_start, x2_start, x3_start, tr->partitionData[model].EV, tr->partitionData[model].tipVector,
newviewGenericSpecial.c:		  if(tr->rateHetModel == CAT)
newviewGenericSpecial.c:		      if(tr->saveMemory)
newviewGenericSpecial.c:			  newviewGTRCATPROT_AVX_GAPPED_SAVE(tInfo->tipCase,  tr->partitionData[model].EV, rateCategory,
newviewGenericSpecial.c:							    x1_start, x2_start, x3_start, tr->partitionData[model].tipVector, (int*)NULL,
newviewGenericSpecial.c:							    x1_gapColumn, x2_gapColumn, x3_gapColumn, tr->maxCategories);
newviewGenericSpecial.c:			  newviewGTRCATPROT_SAVE(tInfo->tipCase,  tr->partitionData[model].EV, rateCategory,
newviewGenericSpecial.c:						 x1_start, x2_start, x3_start, tr->partitionData[model].tipVector,
newviewGenericSpecial.c:						 x1_gapColumn, x2_gapColumn, x3_gapColumn, tr->maxCategories);
newviewGenericSpecial.c:			  newviewGTRCATPROT_AVX(tInfo->tipCase,  tr->partitionData[model].EV, rateCategory,
newviewGenericSpecial.c:						x1_start, x2_start, x3_start, tr->partitionData[model].tipVector,
newviewGenericSpecial.c:			  newviewGTRCATPROT(tInfo->tipCase,  tr->partitionData[model].EV, rateCategory,
newviewGenericSpecial.c:					    x1_start, x2_start, x3_start, tr->partitionData[model].tipVector,
newviewGenericSpecial.c:		      if(tr->saveMemory)
newviewGenericSpecial.c:							      tr->partitionData[model].EV,
newviewGenericSpecial.c:							      tr->partitionData[model].tipVector, (int*)NULL,
newviewGenericSpecial.c:							  tr->partitionData[model].EV,
newviewGenericSpecial.c:							  tr->partitionData[model].tipVector,
newviewGenericSpecial.c:			  if(tr->partitionData[model].protModels == LG4M || tr->partitionData[model].protModels == LG4X)
newviewGenericSpecial.c:							x1_start, x2_start, x3_start, tr->partitionData[model].mic_EV, tr->partitionData[model].mic_tipVector,
newviewGenericSpecial.c:							tr->partitionData[model].mic_umpLeft, tr->partitionData[model].mic_umpRight);
newviewGenericSpecial.c:							  tr->partitionData[model].EV_LG4,
newviewGenericSpecial.c:							  tr->partitionData[model].tipVector_LG4,
newviewGenericSpecial.c:						      tr->partitionData[model].EV_LG4,
newviewGenericSpecial.c:						      tr->partitionData[model].tipVector_LG4,
newviewGenericSpecial.c:							x1_start, x2_start, x3_start, tr->partitionData[model].mic_EV, tr->partitionData[model].mic_tipVector,
newviewGenericSpecial.c:							tr->partitionData[model].mic_umpLeft, tr->partitionData[model].mic_umpRight);
newviewGenericSpecial.c:						       x1_start, x2_start, x3_start, tr->partitionData[model].EV, tr->partitionData[model].tipVector,
newviewGenericSpecial.c:						      x1_start, x2_start, x3_start, tr->partitionData[model].EV, tr->partitionData[model].tipVector,
newviewGenericSpecial.c:						  x1_start, x2_start, x3_start, tr->partitionData[model].EV, tr->partitionData[model].tipVector,
newviewGenericSpecial.c:		  assert(!tr->saveMemory);
newviewGenericSpecial.c:					  x1_start, x2_start, x3_start, tr->partitionData[model].EV, tr->partitionData[model].tipVector,
newviewGenericSpecial.c:		  assert(!tr->saveMemory);
newviewGenericSpecial.c:					  x1_start, x2_start, x3_start, tr->partitionData[model].EV, tr->partitionData[model].tipVector,
newviewGenericSpecial.c:  if(isTip(p->number, tr->mxtips))
newviewGenericSpecial.c:  tr->td[0].count = 0;
newviewGenericSpecial.c:  computeTraversalInfo(p, &(tr->td[0].ti[0]), &(tr->td[0].count), tr->mxtips, tr->numBranches, TRUE);
newviewGenericSpecial.c:  tr->td[0].traversalHasChanged = TRUE;
newviewGenericSpecial.c:     The external boolean array tr->partitionConverged[] contains exactly that information and is copied 
newviewGenericSpecial.c:      for(model = 0; model < tr->NumberOfModels; model++)
newviewGenericSpecial.c:	  if(tr->partitionConverged[model])
newviewGenericSpecial.c:	    tr->executeModel[model] = FALSE;
newviewGenericSpecial.c:	    tr->executeModel[model] = TRUE;
newviewGenericSpecial.c:  if(tr->td[0].count > 0)
newviewGenericSpecial.c:      for(model = 0; model < tr->NumberOfModels; model++)
newviewGenericSpecial.c:	tr->executeModel[model] = TRUE;
newviewGenericSpecial.c:  tr->td[0].traversalHasChanged = FALSE;
optimizeModel.c:    states   = tr->partitionData[model].states,
optimizeModel.c:  if(tr->partitionData[model].dataType == DNA_DATA)
optimizeModel.c:      if(isPomo(tr->partitionData[model].dataType))
optimizeModel.c:  assert(tr->partitionData[model].dataType != BINARY_DATA); 
optimizeModel.c:  if(tr->partitionData[model].nonGTR)
optimizeModel.c:	index = tr->partitionData[model].symmetryVector[position],
optimizeModel.c:	lastRate = tr->partitionData[model].symmetryVector[numRates - 1];   
optimizeModel.c:      assert(!isPomo(tr->partitionData[model].dataType));
optimizeModel.c:	  if(tr->partitionData[model].symmetryVector[i] == index)
optimizeModel.c:		tr->partitionData[model].substRates[i] = 1.0;
optimizeModel.c:		tr->partitionData[model].substRates[i] = rate;      
optimizeModel.c:	  //printf("%f ", tr->partitionData[model].substRates[i]);
optimizeModel.c:      if(isPomo(tr->partitionData[model].dataType))
optimizeModel.c:	tr->partitionData[model].pomoRates[position] = rate;
optimizeModel.c:	tr->partitionData[model].substRates[position] = rate;
optimizeModel.c:  for(i = 0; i < tr->NumberOfModels; i++)    
optimizeModel.c:      assert(linkList[i] >= 0 && linkList[i] < tr->NumberOfModels);
optimizeModel.c:      for(k = 0; k < tr->NumberOfModels; k++)	
optimizeModel.c:      for(k = 0, pos = 0; k < tr->NumberOfModels; k++)	
optimizeModel.c:    *list = (int*)malloc(sizeof(int) * tr->NumberOfModels),
optimizeModel.c:      assert(j < tr->NumberOfModels);
optimizeModel.c:    states = tr->partitionData[model].states,
optimizeModel.c:    tr->partitionData[model].symmetryVector[j] = list[j];    
optimizeModel.c:    tr->partitionData[model].nonGTR = TRUE;
optimizeModel.c:    *links = (int*)malloc(sizeof(int) * tr->NumberOfModels),
optimizeModel.c:    firstAA = tr->NumberOfModels + 2,
optimizeModel.c:  for(i = 0; i < tr->NumberOfModels; i++)
optimizeModel.c:      if(tr->partitionData[i].dataType == AA_DATA)
optimizeModel.c:	  if(tr->partitionData[i].protModels == GTR)
optimizeModel.c:      for(i = 0; i < tr->NumberOfModels; i++)
optimizeModel.c:      for(i = 0; i < tr->NumberOfModels; i++)
optimizeModel.c:	  switch(tr->partitionData[i].dataType)
optimizeModel.c:  tr->partitionData[model].weightExponents[rate] = value;
optimizeModel.c:    w += exp(tr->partitionData[model].weightExponents[j]);
optimizeModel.c:    tr->partitionData[model].weights[j] = exp(tr->partitionData[model].weightExponents[j]) / w;
optimizeModel.c:  evaluateGeneric(tr, tr->start, FALSE);
optimizeModel.c:  initialLH = tr->likelihood;
optimizeModel.c:  //printf("W: %f %f [%f] ->", tr->perPartitionLH[0], tr->perPartitionLH[1], initialLH);
optimizeModel.c:  evaluateGeneric(tr, tr->start, TRUE); 
optimizeModel.c:  finalLH = tr->likelihood;
optimizeModel.c:  //printf("%f %f [%f]\n",  tr->perPartitionLH[0], tr->perPartitionLH[1], finalLH);
optimizeModel.c:      tr->partitionData[index].alpha = value;
optimizeModel.c:      makeGammaCats(tr->partitionData[index].alpha, tr->partitionData[index].gammaRates, 4, tr->useMedian);
optimizeModel.c:	if(isPomo(tr->partitionData[index].dataType))
optimizeModel.c:	  states = tr->partitionData[index].states;
optimizeModel.c:	tr->partitionData[index].freqExponents[rateNumber] = value;
optimizeModel.c:	  w += exp(tr->partitionData[index].freqExponents[j]);
optimizeModel.c:	if(isPomo(tr->partitionData[index].dataType))
optimizeModel.c:	    tr->partitionData[index].pomoFrequencies[j] = exp(tr->partitionData[index].freqExponents[j]) / w;
optimizeModel.c:	    tr->partitionData[index].frequencies[j] = exp(tr->partitionData[index].freqExponents[j]) / w;
optimizeModel.c:      tr->partitionData[index].gammaRates[rateNumber] = value;
optimizeModel.c:      tr->partitionData[index].pomoPhi = value;
optimizeModel.c:		tr->executeModel[ll->ld[i].partitionList[k]] = FALSE;
optimizeModel.c:	    tr->executeModel[ll->ld[i].partitionList[k]] = FALSE;	     
optimizeModel.c:      evaluateGeneric(tr, tr->start, TRUE);      
optimizeModel.c:      evaluateGeneric(tr, tr->start, FALSE);  
optimizeModel.c:	*buffer = (boolean*)malloc(tr->NumberOfModels * sizeof(boolean));
optimizeModel.c:      memcpy(buffer, tr->executeModel, sizeof(boolean) * tr->NumberOfModels);
optimizeModel.c:      for(i = 0; i < tr->NumberOfModels; i++)
optimizeModel.c:	tr->executeModel[i] = FALSE;
optimizeModel.c:	    tr->executeModel[index] = TRUE;	    
optimizeModel.c:      memcpy(tr->executeModel, buffer, sizeof(boolean) * tr->NumberOfModels);
optimizeModel.c:  //evaluateGeneric(tr, tr->start, TRUE);  
optimizeModel.c:	      assert(tr->perPartitionLH[index] <= 0.0);
optimizeModel.c:	      result[pos] -= tr->perPartitionLH[index];
optimizeModel.c:	  tr->executeModel[index] = TRUE;
optimizeModel.c:    *lg4xScalers = (double *)calloc(tr->NumberOfModels, sizeof(double)),   
optimizeModel.c:  for(i = 0; i < tr->NumberOfModels; i++)
optimizeModel.c:	    averageRate += tr->partitionData[index].gammaRates[j];	  
optimizeModel.c:  if(tr->NumberOfModels > 1)
optimizeModel.c:      for(i = 0; i < tr->NumberOfModels; i++)
optimizeModel.c:	tr->fracchanges[i] = tr->rawFracchanges[i] * (1.0 / lg4xScalers[i]);
optimizeModel.c:  for(i = 0; i < tr->NumberOfModels; i++)         
optimizeModel.c:    wgtsum += (double)tr->partitionWeights[i];
optimizeModel.c:  for(i = 0; i < tr->NumberOfModels; i++)
optimizeModel.c:	fraction = (double)tr->partitionWeights[i] / wgtsum; 
optimizeModel.c:  tr->fracchange = tr->rawFracchange * (1.0 / lg4xScaler);
optimizeModel.c:      switch(tr->partitionData[ll->ld[i].partitionList[0]].dataType)
optimizeModel.c:	  if(tr->partitionData[ll->ld[i].partitionList[0]].protModels == LG4X)
optimizeModel.c:      switch(tr->partitionData[ll->ld[i].partitionList[0]].dataType)
optimizeModel.c:	  if(tr->partitionData[ll->ld[i].partitionList[0]].protModels == LG4X)	      
optimizeModel.c:      switch(tr->partitionData[ll->ld[i].partitionList[0]].dataType)
optimizeModel.c:    *w = tr->partitionData[index].freqExponents,
optimizeModel.c:  if(isPomo(tr->partitionData[index].dataType))
optimizeModel.c:    states = tr->partitionData[index].states;
optimizeModel.c:    *w = tr->partitionData[index].freqExponents,
optimizeModel.c:  if(isPomo(tr->partitionData[index].dataType))
optimizeModel.c:    states = tr->partitionData[index].states;
optimizeModel.c:    evaluateGeneric(tr, tr->start, FALSE);
optimizeModel.c:      evaluateGeneric(tr, tr->start, TRUE);
optimizeModel.c:	  for(j = 0; j < tr->NumberOfModels; j++)
optimizeModel.c:	    tr->partitionData[j].weightLikelihood = tr->perPartitionLH[j];
optimizeModel.c:    initialLH = tr->likelihood;
optimizeModel.c:	      startLH[pos] += tr->perPartitionLH[index];
optimizeModel.c:		  startValues[pos] = tr->partitionData[index].alpha;
optimizeModel.c:		  if(isPomo(tr->partitionData[index].dataType))
optimizeModel.c:		    startValues[pos] = tr->partitionData[index].pomoRates[rateNumber]; 
optimizeModel.c:		    startValues[pos] = tr->partitionData[index].substRates[rateNumber];      
optimizeModel.c:		  startValues[pos] = tr->partitionData[index].freqExponents[rateNumber];
optimizeModel.c:		  startValues[pos] = tr->partitionData[index].gammaRates[rateNumber];
optimizeModel.c:		  memcpy(&startRates[pos * 4],   tr->partitionData[index].gammaRates, 4 * sizeof(double)); 
optimizeModel.c:		  memcpy(&startExponents[pos * 4], tr->partitionData[index].weightExponents, 4 * sizeof(double));
optimizeModel.c:		  memcpy(&startWeights[pos * 4], tr->partitionData[index].weights,    4 * sizeof(double));
optimizeModel.c:		  startValues[pos] = tr->partitionData[index].weightExponents[rateNumber];		  
optimizeModel.c:		  startValues[pos] = tr->partitionData[index].pomoPhi;
optimizeModel.c:		      memcpy(tr->partitionData[index].weights,         &startWeights[pos * 4], sizeof(double) * 4);
optimizeModel.c:		      memcpy(tr->partitionData[index].gammaRates,      &startRates[pos * 4], sizeof(double) * 4);
optimizeModel.c:		      memcpy(tr->partitionData[index].weightExponents, &startExponents[pos * 4], 4 * sizeof(double));
optimizeModel.c:		      if(endLH[pos] > tr->partitionData[index].weightLikelihood)
optimizeModel.c:			  memcpy(tr->partitionData[index].weightsBuffer,         tr->partitionData[index].weights, sizeof(double) * 4);
optimizeModel.c:			  memcpy(tr->partitionData[index].weightExponentsBuffer, tr->partitionData[index].weightExponents, sizeof(double) * 4);
optimizeModel.c:			  tr->partitionData[index].weightLikelihood = endLH[pos];
optimizeModel.c:		      memcpy(tr->partitionData[index].weights,         tr->partitionData[index].weightsBuffer, sizeof(double) * 4);		 
optimizeModel.c:		      memcpy(tr->partitionData[index].weightExponents, tr->partitionData[index].weightExponentsBuffer, sizeof(double) * 4);
optimizeModel.c:  evaluateGeneric(tr, tr->start, TRUE);
optimizeModel.c:  if(tr->likelihood < initialLH)
optimizeModel.c:    printf("%f %f\n", tr->likelihood, initialLH);
optimizeModel.c:  assert(tr->likelihood >= initialLH);
optimizeModel.c:      switch(tr->partitionData[ll->ld[i].partitionList[0]].dataType)
optimizeModel.c:	  states = tr->partitionData[ll->ld[i].partitionList[0]].states;	 
optimizeModel.c:	  if(tr->partitionData[ll->ld[i].partitionList[0]].optimizeBaseFrequencies)
optimizeModel.c:      switch(tr->partitionData[ll->ld[i].partitionList[0]].dataType)
optimizeModel.c:	  states = tr->partitionData[ll->ld[i].partitionList[0]].states;	 
optimizeModel.c:	  if(tr->partitionData[ll->ld[i].partitionList[0]].optimizeBaseFrequencies)
optimizeModel.c:      switch(tr->partitionData[ll->ld[i].partitionList[0]].dataType)
optimizeModel.c:	  states = tr->partitionData[ll->ld[i].partitionList[0]].states; 	      
optimizeModel.c:	  if(tr->partitionData[ll->ld[i].partitionList[0]].optimizeBaseFrequencies)
optimizeModel.c:      switch(tr->partitionData[ll->ld[i].partitionList[0]].dataType)
optimizeModel.c:	  states = tr->partitionData[ll->ld[i].partitionList[0]].states; 	      
optimizeModel.c:	  if(tr->partitionData[ll->ld[i].partitionList[0]].optimizeBaseFrequencies)
optimizeModel.c:  for(i = 0; i < tr->NumberOfModels; i++)   
optimizeModel.c:      if(tr->partitionData[i].dataType == AA_DATA)
optimizeModel.c:	  if(tr->partitionData[i].protModels != GTR)
optimizeModel.c:      switch(tr->partitionData[ll->ld[i].partitionList[0]].dataType)
optimizeModel.c:	  states = tr->partitionData[ll->ld[i].partitionList[0]].states;	 
optimizeModel.c:      switch(tr->partitionData[ll->ld[i].partitionList[0]].dataType)
optimizeModel.c:	  states = tr->partitionData[ll->ld[i].partitionList[0]].states;	 
optimizeModel.c:	  switch(tr->partitionData[ll->ld[i].partitionList[0]].dataType)
optimizeModel.c:	      states = tr->partitionData[ll->ld[i].partitionList[0]].states; 	      
optimizeModel.c:				int *rateCategory /* temporary; used to be tr->rateCategory */ 
optimizeModel.c:      for(k = 0; k < tr->partitionData[model].numberOfCategories; k++)
optimizeModel.c:	  for(k = 1; k < tr->partitionData[model].numberOfCategories; k++)
optimizeModel.c:  for(k = 0; k < tr->partitionData[model].numberOfCategories; k++)
optimizeModel.c:    tr->partitionData[model].perSiteRates[k] = rc[k].rate; 
optimizeModel.c:    maxModel = tr->maxModelsPerThread;
optimizeModel.c:    maxModel = tr->NumberOfModels;
optimizeModel.c:	    pAss = tr->threadPartAssigns[tid * tr->maxModelsPerThread + m];
optimizeModel.c:	      assert(model < tr->NumberOfModels);
optimizeModel.c:	  width  = (size_t)tr->partitionData[model].width;
optimizeModel.c:	*partition = &(tr->partitionData[model]); 
optimizeModel.c:  *weightPerPart_result = (int*)calloc((size_t)tr->NumberOfModels, sizeof(int)); 
optimizeModel.c:  *weightedRates_result = (double*) calloc((size_t)tr->NumberOfModels, sizeof(double)); 
optimizeModel.c:  for(i = 0; i < tr->NumberOfModels; ++i)
optimizeModel.c:	*partition = &(tr->partitionData[i]); 
optimizeModel.c:	  assert(0 <= c && c < tr->maxCategories); 
optimizeModel.c:  MPI_Allreduce(MPI_IN_PLACE, weightPerPart, tr->NumberOfModels, MPI_INT, MPI_SUM, MPI_COMM_WORLD);
optimizeModel.c:  MPI_Allreduce(MPI_IN_PLACE, weightedRates, tr->NumberOfModels, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD); 
optimizeModel.c:  for( i = 0; i < tr->NumberOfModels; ++i)
optimizeModel.c:  if(tr->numBranches > 1 )
optimizeModel.c:      for(i = 0; i < tr->NumberOfModels; ++i)
optimizeModel.c:      for(i = 0; i < tr->NumberOfModels; ++i)
optimizeModel.c:  if(tr->numBranches > 1  )	
optimizeModel.c:      for(i = 0; i < tr->NumberOfModels; ++i)
optimizeModel.c:	  for(j = 0; j < tr->partitionData[i].numberOfCategories; ++j)
optimizeModel.c:	    tr->partitionData[i].perSiteRates[j] *= scaler; 
optimizeModel.c:      for(i = 0; i < tr->NumberOfModels; ++i)
optimizeModel.c:      for(i = 0; i < tr->NumberOfModels; ++i)
optimizeModel.c:	    *partition = &(tr->partitionData[i]); 
optimizeModel.c:  Notice that for instance tr->patrat_basePtr already contain all rate
optimizeModel.c:  optRates_result  -- (only at master) a pointer to an array of optimized rates (corresponds to what used to be  tr->patratStored)
optimizeModel.c:  lnls_result -- (only at master) a pointer to an array with persite-lnls that correspond to the newly proposed rate  (used to be tr->lhs) 
optimizeModel.c:  gatherDistributedArray( tr, (void**) optRates_result, tr->patrat_basePtr, MPI_DOUBLE, numPerProc, displPerProc); 
optimizeModel.c:  gatherDistributedArray(tr , (void**) lnls_result, tr->lhs_basePtr, MPI_DOUBLE, numPerProc, displPerProc); 
optimizeModel.c:   patrat  -- a global array of  optimized rates (used to be tr->patratStored)  
optimizeModel.c:   lnls -- a global array of per-site lnls (used to be tr->lhs)
optimizeModel.c:   rateCategory_result  -- a pointer to a global array of rate categories (used to be tr->rateCategory) 
optimizeModel.c:   tr->partitionData[i].perSiteRates gets computed in categorizePartition.
optimizeModel.c:  *rateCategory_result = (int*) calloc((size_t)tr->originalCrunchedLength, sizeof(int)); 
optimizeModel.c:  for(model = 0; model < tr->NumberOfModels; model++)
optimizeModel.c:	width = tr->partitionData[model].upper -  tr->partitionData[model].lower,
optimizeModel.c:	upper = tr->partitionData[model].upper,
optimizeModel.c:	lower = tr->partitionData[model].lower;
optimizeModel.c:	  tr->partitionData[model].numberOfCategories = where;
optimizeModel.c:	  tr->partitionData[model].numberOfCategories = maxCategories;	
optimizeModel.c:    *numCatPerPart = (int*) calloc((size_t)tr->NumberOfModels, sizeof(int)); 
optimizeModel.c:      for(i = 0; i < tr->NumberOfModels; ++i)
optimizeModel.c:	numCatPerPart[i] = tr->partitionData[i].numberOfCategories; 
optimizeModel.c:  MPI_Bcast(numCatPerPart, tr->NumberOfModels,  MPI_INT, 0,MPI_COMM_WORLD); 
optimizeModel.c:  for(i = 0; i < tr->NumberOfModels; ++i)
optimizeModel.c:    tr->partitionData[i].numberOfCategories = numCatPerPart[i]; 
optimizeModel.c:  for(i = 0; i < tr->NumberOfModels; ++i)
optimizeModel.c:    MPI_Bcast(tr->partitionData[i].perSiteRates, tr->maxCategories, MPI_DOUBLE, 0, MPI_COMM_WORLD);
optimizeModel.c:      for(i = 0; i < tr->originalCrunchedLength; ++i)
optimizeModel.c:  scatterDistrbutedArray(tr, rateCategory, tr->rateCategory_basePtr, MPI_INT, countPerProc, displPerProc); 
optimizeModel.c:    printf("%d,", tr->rateCategory_basePtr[i]);
optimizeModel.c:    numCat = tr->maxCategories;
optimizeModel.c:  *resultPtr = (RateBackup* ) calloc((size_t)tr->NumberOfModels, sizeof(RateBackup));
optimizeModel.c:  for(i = 0; i < tr->NumberOfModels; ++i)
optimizeModel.c:	*partition = &(tr->partitionData[i]); 
optimizeModel.c:    numCat = tr->maxCategories,
optimizeModel.c:  for(i = 0; i < tr->NumberOfModels; ++i)
optimizeModel.c:	*partition = &(tr->partitionData[i]); 
optimizeModel.c:  for(i = 0; i< tr->NumberOfModels; ++i)
optimizeModel.c:    initialLH = tr->likelihood,
optimizeModel.c:  assert(isTip(tr->start->number, tr->mxtips));         
optimizeModel.c:  evaluateGeneric(tr, tr->start, TRUE);     
optimizeModel.c:  evaluateGeneric(tr, tr->start, TRUE);
optimizeModel.c:  if(tr->likelihood < initialLH)
optimizeModel.c:      evaluateGeneric(tr, tr->start, TRUE);	 
optimizeModel.c:      assert(initialLH == tr->likelihood);
optimizeModel.c:  nodes = tr->mxtips  +  3 * (tr->mxtips - 2);
optimizeModel.c:  p = tr->nodep[1];
optimizeModel.c:      for(i = 0; i < tr->numBranches; i++)
optimizeModel.c:	  for(i = 0; i < tr->numBranches; i++)
optimizeModel.c:      for(model = 0; model < tr->NumberOfModels; model++)
optimizeModel.c:	  if(tr->partitionData[model].dataType == AA_DATA) 
optimizeModel.c:	      double *rates = tr->partitionData[model].substRates;
optimizeModel.c:	      double *f     = tr->partitionData[model].frequencies;
optimizeModel.c:	      assert(tr->partitionData[model].protModels == GTR);
optimizeModel.c:  for(model = 0; model < tr->NumberOfModels; model++)
optimizeModel.c:      for(model = 0; model < tr->NumberOfModels; model++)
optimizeModel.c:	  if(tr->partitionData[model].protModels == AUTO)
optimizeModel.c:		tr->partitionData[model].protFreqs = 0;
optimizeModel.c:		tr->partitionData[model].protFreqs = 1;
optimizeModel.c:	      assert(!tr->partitionData[model].optimizeBaseFrequencies);
optimizeModel.c:	      tr->partitionData[model].autoProtModels = i;
optimizeModel.c:      evaluateGeneric(tr, tr->start, TRUE);  
optimizeModel.c:      //printf("Subst Model %d Freqs: %s like %f %f\n", i, (empiricalFreqs == TRUE)?"empirical":"fixed", tr->likelihood, tr->perPartitionLH[0]);
optimizeModel.c:      for(model = 0; model < tr->NumberOfModels; model++)
optimizeModel.c:	  if(tr->partitionData[model].protModels == AUTO)
optimizeModel.c:		    printf("%f ", tr->partitionData[model].frequencies[k]);
optimizeModel.c:	      if(tr->perPartitionLH[model] > bestScores[model])
optimizeModel.c:		  bestScores[model] = tr->perPartitionLH[model];
optimizeModel.c:  for(model = 0; model < tr->NumberOfModels; model++)	      
optimizeModel.c:    if(tr->partitionData[model].protModels == AUTO)
optimizeModel.c:	*bestIndex = (int*)malloc(sizeof(int) * tr->NumberOfModels),
optimizeModel.c:	*oldIndex  = (int*)malloc(sizeof(int) * tr->NumberOfModels),
optimizeModel.c:	*bestIndexEmpFreqs = (int*)malloc(sizeof(int) * tr->NumberOfModels);
optimizeModel.c:	*oldFreqs =  (boolean*)malloc(sizeof(boolean) * tr->NumberOfModels);
optimizeModel.c:	*bestScores         = (double*)malloc(sizeof(double) * tr->NumberOfModels),
optimizeModel.c:	*bestScoresEmpFreqs = (double*)malloc(sizeof(double) * tr->NumberOfModels);
optimizeModel.c:      evaluateGeneric(tr, tr->start, TRUE); 
optimizeModel.c:      startLH = tr->likelihood;
optimizeModel.c:      for(model = 0; model < tr->NumberOfModels; model++)
optimizeModel.c:	  oldIndex[model] = tr->partitionData[model].autoProtModels;
optimizeModel.c:	  oldFreqs[model] = tr->partitionData[model].protFreqs;
optimizeModel.c:      printBothOpen("Automatic protein model assignment algorithm using %s criterion:\n\n", autoModels[tr->autoProteinSelectionType]);
optimizeModel.c:      for(model = 0; model < tr->NumberOfModels; model++)
optimizeModel.c:	  if(tr->partitionData[model].protModels == AUTO)
optimizeModel.c:	      samples = tr->partitionWeights[model]; 
optimizeModel.c:	      assert(tr->ntips == tr->mxtips);
optimizeModel.c:	      freeParamsFixed = freeParamsEmp = (2 * tr->ntips - 3);
optimizeModel.c:	      switch(tr->rateHetModel)
optimizeModel.c:		  freeParamsFixed += (double)tr->partitionData[model].numberOfCategories;
optimizeModel.c:		  freeParamsEmp += (double)tr->partitionData[model].numberOfCategories;
optimizeModel.c:	      switch(tr->autoProteinSelectionType)
optimizeModel.c:		      tr->partitionData[model].autoProtModels = bestIndexFixed;
optimizeModel.c:		      tr->partitionData[model].protFreqs = 1;
optimizeModel.c:		      tr->partitionData[model].autoProtModels = bestIndexEmp;
optimizeModel.c:		      tr->partitionData[model].protFreqs = 0;
optimizeModel.c:			tr->partitionData[model].autoProtModels = bestIndexFixed;
optimizeModel.c:			tr->partitionData[model].protFreqs = 1;
optimizeModel.c:			tr->partitionData[model].autoProtModels = bestIndexEmp;
optimizeModel.c:			tr->partitionData[model].protFreqs = 0;
optimizeModel.c:			tr->partitionData[model].autoProtModels = bestIndexFixed;
optimizeModel.c:			tr->partitionData[model].protFreqs = 1;
optimizeModel.c:			tr->partitionData[model].autoProtModels = bestIndexEmp;
optimizeModel.c:			tr->partitionData[model].protFreqs = 0;
optimizeModel.c:			tr->partitionData[model].autoProtModels = bestIndexFixed;
optimizeModel.c:			tr->partitionData[model].protFreqs = 1;
optimizeModel.c:			tr->partitionData[model].autoProtModels = bestIndexEmp;
optimizeModel.c:			tr->partitionData[model].protFreqs = 0;
optimizeModel.c:			    model, protModels[tr->partitionData[model].autoProtModels],  
optimizeModel.c:			    (tr->partitionData[model].protFreqs == 1)?bestLhFixed:bestLhEmp, 
optimizeModel.c:			    (tr->partitionData[model].protFreqs == 1)?"fixed":"empirical");
optimizeModel.c:      evaluateGeneric(tr, tr->start, TRUE); 
optimizeModel.c:      //printf("exit %f\n", tr->likelihood);
optimizeModel.c:      if(tr->likelihood < startLH)
optimizeModel.c:	  for(model = 0; model < tr->NumberOfModels; model++)
optimizeModel.c:	      if(tr->partitionData[model].protModels == AUTO)
optimizeModel.c:		  tr->partitionData[model].autoProtModels = oldIndex[model];
optimizeModel.c:		  tr->partitionData[model].protFreqs = oldFreqs[model] ;
optimizeModel.c:	  evaluateGeneric(tr, tr->start, TRUE);              
optimizeModel.c:      assert(tr->likelihood >= startLH);
optimizeModel.c:		states = tr->partitionData[index].states,
optimizeModel.c:	      if(tr->partitionData[reference].nonGTR != tr->partitionData[index].nonGTR)
optimizeModel.c:	      if(tr->partitionData[reference].nonGTR)
optimizeModel.c:		      if(tr->partitionData[reference].symmetryVector[j] != tr->partitionData[index].symmetryVector[j])
optimizeModel.c:    *unlinked = (int *)malloc(sizeof(int) * tr->NumberOfModels);  
optimizeModel.c:  for(i = 0; i < tr->NumberOfModels; i++)    
optimizeModel.c:  tr->start = tr->nodep[1];
optimizeModel.c:  inputLikelihood = tr->likelihood;
optimizeModel.c:  evaluateGeneric(tr, tr->start, TRUE); 
optimizeModel.c:  assert(inputLikelihood == tr->likelihood);
optimizeModel.c:      currentLikelihood = tr->likelihood;     
optimizeModel.c:      evaluateGeneric(tr, tr->start, TRUE);    
optimizeModel.c:      printf("after rates %f\n", tr->likelihood);
optimizeModel.c:      evaluateGeneric(tr, tr->start, TRUE); 
optimizeModel.c:      printf("after br-len 1 %f\n", tr->likelihood);
optimizeModel.c:      evaluateGeneric(tr, tr->start, TRUE);
optimizeModel.c:      evaluateGeneric(tr, tr->start, TRUE);
optimizeModel.c:      evaluateGeneric(tr, tr->start, TRUE); 
optimizeModel.c:      printf("after optBaseFreqs 1 %f\n", tr->likelihood);
optimizeModel.c:      evaluateGeneric(tr, tr->start, TRUE);
optimizeModel.c:      switch(tr->rateHetModel)
optimizeModel.c:	  evaluateGeneric(tr, tr->start, TRUE); 
optimizeModel.c:	  printf("after alphas %f\n", tr->likelihood);
optimizeModel.c:	  evaluateGeneric(tr, tr->start, TRUE); 
optimizeModel.c:	  printf("after br-len 2 %f\n", tr->likelihood);
optimizeModel.c:	      evaluateGeneric(tr, tr->start, TRUE);
optimizeModel.c:	      optimizeRateCategories(tr, tr->categories);	      	     	      	      	     
optimizeModel.c:	      evaluateGeneric(tr, tr->start, TRUE); 
optimizeModel.c:	      printf("after cat-opt %f\n", tr->likelihood);
optimizeModel.c:      checkTolerance(tr->likelihood, currentLikelihood);
optimizeModel.c:	if(tr->likelihood < currentLikelihood)
optimizeModel.c:	printf("%f %f\n", tr->likelihood, currentLikelihood);
optimizeModel.c:	assert(tr->likelihood >= currentLikelihood);
optimizeModel.c:      printAAmatrix(tr, fabs(currentLikelihood - tr->likelihood));            
optimizeModel.c:  while(fabs(currentLikelihood - tr->likelihood) > likelihoodEpsilon);  
partitionAssignment.c:  for(i = 0; i < tr->NumberOfModels; ++i)
partitionAssignment.c:    len += tr->partitionData[i].width ; 
partitionAssignment.c:  tr->patrat_basePtr = (double*) calloc((size_t)len, sizeof(double));
partitionAssignment.c:  tr->rateCategory_basePtr = (int*) calloc((size_t)len, sizeof(int)); 
partitionAssignment.c:  tr->lhs_basePtr = (double*) calloc((size_t)len, sizeof(double)); 
partitionAssignment.c:  for(i = 0; i < tr->NumberOfModels; ++i)
partitionAssignment.c:      if(tr->partitionData[i].width > 0)
partitionAssignment.c:	  tr->partitionData[i].rateCategory = tr->rateCategory_basePtr + len; 
partitionAssignment.c:	  tr->partitionData[i].patrat = tr->patrat_basePtr + len; 
partitionAssignment.c:	  tr->partitionData[i].lhs = tr->lhs_basePtr + len ; 
partitionAssignment.c:	  tr->partitionData[i].rateCategory = (int *)NULL; 
partitionAssignment.c:	  tr->partitionData[i].patrat = (double*)NULL; 
partitionAssignment.c:	  tr->partitionData[i].lhs = (double*)NULL;
partitionAssignment.c:      len += tr->partitionData[i].width; 
partitionAssignment.c:  tr->numAssignments  = numAssign; 
partitionAssignment.c:  tr->partAssigns = (Assign *)calloc((size_t)numAssign, sizeof(Assign)); 
partitionAssignment.c:  assIter = tr->partAssigns; 
partitionAssignment.c:  qsort(tr->partAssigns, (size_t)tr->numAssignments, sizeof(Assign), sortById);
partitionAssignment.c:  if(tr->rateHetModel == CAT)
partitionAssignment.c:  tr->maxModelsPerThread = numsPerProc[pmax];
partitionAssignment.c:  assert(tr->maxModelsPerThread > 0 && tr->maxModelsPerThread <= pa->numPartitions);
partitionAssignment.c:  tr->maxThreadsPerModel = numsPerPart[pmax];
partitionAssignment.c:  assert(tr->maxThreadsPerModel > 0 && tr->maxThreadsPerModel <= pa->numProc);
partitionAssignment.c:  printf("\n maxModelsPerThread: %d,   maxThreadsPerModel: %d\n", tr->maxModelsPerThread, tr->maxThreadsPerModel);
partitionAssignment.c:    threadPartSize = pa->numProc * tr->maxModelsPerThread,
partitionAssignment.c:    partThreadSize = pa->numPartitions * tr->maxThreadsPerModel;
partitionAssignment.c:  tr->threadPartAssigns = (Assign **)calloc((size_t)threadPartSize, sizeof(Assign*));
partitionAssignment.c:  tr->partThreadAssigns = (Assign **)calloc((size_t)partThreadSize, sizeof(Assign*));
partitionAssignment.c:	    ind = i * tr->maxModelsPerThread + partCount;
partitionAssignment.c:	  assert(ind < (i+1) * tr->maxModelsPerThread);
partitionAssignment.c:	  tr->threadPartAssigns[ind] = pTreeAss;
partitionAssignment.c:	  ind = ass->partId * tr->maxThreadsPerModel;
partitionAssignment.c:	  while (tr->partThreadAssigns[ind])
partitionAssignment.c:	  assert( ind < (ass->partId+1) * tr->maxThreadsPerModel);
partitionAssignment.c:	  tr->partThreadAssigns[ind] = pTreeAss;
restartHashTable.c:  int lookup = lookupWord(str, tr->nameHash);
restartHashTable.c:      assert(! tr->nodep[lookup]->back);
restartHashTable.c:      n = (tr->nextnode)++;
restartHashTable.c:      if (n > 2*(tr->mxtips) - 2) 
restartHashTable.c:	  if (tr->rooted || n > 2*(tr->mxtips) - 1) 
restartHashTable.c:	      tr->rooted = TRUE;
restartHashTable.c:      q = tr->nodep[n];
restartHashTable.c:      q = tr->nodep[n];
restartHashTable.c:      if (tr->start->number > n)  
restartHashTable.c:	tr->start = q;
restartHashTable.c:      (tr->ntips)++;
restartHashTable.c:  hookupDefault(p, q, tr->numBranches);
restartHashTable.c:  for(i = 1; i <= tr->mxtips; i++)    
restartHashTable.c:    tr->nodep[i]->back = (node *)NULL;      
restartHashTable.c:  for(i = tr->mxtips + 1; i < 2 * tr->mxtips; i++)
restartHashTable.c:      tr->nodep[i]->back = (nodeptr)NULL;
restartHashTable.c:      tr->nodep[i]->next->back = (nodeptr)NULL;
restartHashTable.c:      tr->nodep[i]->next->next->back = (nodeptr)NULL;
restartHashTable.c:      tr->nodep[i]->number = i;
restartHashTable.c:      tr->nodep[i]->next->number = i;
restartHashTable.c:      tr->nodep[i]->next->next->number = i;           
restartHashTable.c:  tr->start       = tr->nodep[1];
restartHashTable.c:  tr->ntips       = 0;
restartHashTable.c:  tr->nextnode    = tr->mxtips + 1;    
restartHashTable.c:  tr->rooted      = FALSE;      
restartHashTable.c:  p = tr->nodep[(tr->nextnode)++]; 
restartHashTable.c:  if(!tr->rooted) 
restartHashTable.c:  if(tr->rooted)     
restartHashTable.c:    tr->start = tr->nodep[1];   
searchAlgo.c:  int group = tr->constraintVector[p->number];
searchAlgo.c:  if(isTip(p->number, tr->mxtips))
searchAlgo.c:      group = tr->constraintVector[p->number];
searchAlgo.c:  if (!isTip(p->number, tr->mxtips)) 
searchAlgo.c:  startLH = tr->likelihood;
searchAlgo.c:  for(i = 0; i < tr->numBranches; i++)
searchAlgo.c:  if(tr->numBranches > 1)
searchAlgo.c:  for(i = 0; i < tr->numBranches; i++)    
searchAlgo.c:    smoothedPartitions[i]  = tr->partitionSmoothed[i];
searchAlgo.c:  for(i = 0; i < tr->numBranches; i++)
searchAlgo.c:      if(!tr->partitionConverged[i])
searchAlgo.c:  if(tr->likelihood <= startLH)
searchAlgo.c:      if(fabs(tr->likelihood - startLH) > 0.01)
searchAlgo.c:	  printf("%f %f\n", startLH, tr->likelihood);
searchAlgo.c:  for(i = 0; i < tr->numBranches; i++)    
searchAlgo.c:    tr->partitionSmoothed[i]  = smoothedPartitions[i];
searchAlgo.c:  if (! isTip(p->number, tr->mxtips)) 
searchAlgo.c:      if(tr->numBranches > 1)
searchAlgo.c:  for(i = 0; i < tr->numBranches; i++)
searchAlgo.c:      if(tr->partitionSmoothed[i] == FALSE)
searchAlgo.c:	tr->partitionConverged[i] = TRUE;
searchAlgo.c:  p = tr->start;
searchAlgo.c:  for(i = 0; i < tr->numBranches; i++)
searchAlgo.c:    tr->partitionConverged[i] = FALSE;
searchAlgo.c:      for(i = 0; i < tr->numBranches; i++)	
searchAlgo.c:	tr->partitionSmoothed[i] = TRUE;		
searchAlgo.c:      if (!isTip(p->number, tr->mxtips)) 
searchAlgo.c:  for(i = 0; i < tr->numBranches; i++)
searchAlgo.c:    tr->partitionConverged[i] = FALSE;
searchAlgo.c:  if (isTip(p->number, tr->mxtips)) return FALSE;
searchAlgo.c:   for(i = 0; i < tr->numBranches; i++)	
searchAlgo.c:     tr->partitionConverged[i] = FALSE;	
searchAlgo.c:      for(i = 0; i < tr->numBranches; i++)	
searchAlgo.c:	tr->partitionSmoothed[i] = TRUE;
searchAlgo.c:  for(i = 0; i < tr->numBranches; i++)
searchAlgo.c:      tr->partitionSmoothed[i] = FALSE; 
searchAlgo.c:      tr->partitionConverged[i] = FALSE;
searchAlgo.c:      if (!isTip(p->number, tr->mxtips)) 
searchAlgo.c:    if (isTip(p->number, tr->mxtips)) return FALSE;            /* Should be an error */
searchAlgo.c:    for(i = 0; i < tr->numBranches; i++)
searchAlgo.c:      tr->partitionConverged[i] = FALSE;
searchAlgo.c:	for(i = 0; i < tr->numBranches; i++)	  
searchAlgo.c:	  tr->partitionSmoothed[i] = TRUE;
searchAlgo.c:    for(i = 0; i < tr->numBranches; i++)
searchAlgo.c:      tr->partitionSmoothed[i] = FALSE;
searchAlgo.c:    for(i = 0; i < tr->numBranches; i++)
searchAlgo.c:      tr->partitionConverged[i] = FALSE;
searchAlgo.c:    tr->zqr[i] = result[i];
searchAlgo.c:  hookup(q, r, tr->currentZQR, tr->numBranches);
searchAlgo.c:    tr->lzi[i] = q->z[i];
searchAlgo.c:      hookup(p->next,       q, z, tr->numBranches);
searchAlgo.c:      hookup(p->next->next, r, z, tr->numBranches);	                         
searchAlgo.c:	  tr->lzq[i] = p->next->z[i];
searchAlgo.c:	  tr->lzr[i] = p->next->next->z[i];
searchAlgo.c:	  tr->lzs[i] = p->z[i];            
searchAlgo.c:      hookup(p->next,       q, tr->currentLZQ, tr->numBranches);
searchAlgo.c:      hookup(p->next->next, r, tr->currentLZR, tr->numBranches);
searchAlgo.c:      hookup(p,             s, tr->currentLZS, tr->numBranches);      		  
searchAlgo.c:      for(i = 0; i < tr->numBranches; i++)
searchAlgo.c:      hookup(p->next,       q, z, tr->numBranches);
searchAlgo.c:      hookup(p->next->next, r, z, tr->numBranches);
searchAlgo.c:  nodeptr p = tr->removeNode;
searchAlgo.c:  nodeptr q = tr->insertNode;
searchAlgo.c:  double currentLH = tr->likelihood;
searchAlgo.c:  for(i = 0; i < tr->numBranches; i++)
searchAlgo.c:  hookup(p1, p2, tr->currentZQR, tr->numBranches);
searchAlgo.c:  for(i = 0; i < tr->numBranches; i++)
searchAlgo.c:      hookup(p->next,       q, tr->currentLZQ, tr->numBranches);
searchAlgo.c:      hookup(p->next->next, r, tr->currentLZR, tr->numBranches);
searchAlgo.c:      hookup(p,             s, tr->currentLZS, tr->numBranches);      		  
searchAlgo.c:      for(i = 0; i < tr->numBranches; i++)
searchAlgo.c:      hookup(p->next,       q, z, tr->numBranches);
searchAlgo.c:      hookup(p->next->next, r, z, tr->numBranches);
searchAlgo.c:  tr->likelihood = tr->bestOfNode;
searchAlgo.c:  if(tr->saveBestTrees)
searchAlgo.c:  tr->likelihood = currentLH;
searchAlgo.c:  hookup(q, r, qz, tr->numBranches);
searchAlgo.c:    hookup(p, s, pz, tr->numBranches);          
searchAlgo.c:  hookup(p->next,       p1, p1z, tr->numBranches); 
searchAlgo.c:  hookup(p->next->next, p2, p2z, tr->numBranches);      
searchAlgo.c:  double startLH = tr->endLH;
searchAlgo.c:  for(i = 0; i < tr->numBranches; i++)
searchAlgo.c:  if(tr->constraintTree)
searchAlgo.c:      rNumber = tr->constraintVector[r->number];
searchAlgo.c:      qNumber = tr->constraintVector[q->number];
searchAlgo.c:      pNumber = tr->constraintVector[p->number];
searchAlgo.c:      if (! insertBIG(tr, p, q, tr->numBranches))       return FALSE;         
searchAlgo.c:      if(tr->likelihood > tr->bestOfNode)
searchAlgo.c:	  tr->bestOfNode = tr->likelihood;
searchAlgo.c:	  tr->insertNode = q;
searchAlgo.c:	  tr->removeNode = p;   
searchAlgo.c:	  for(i = 0; i < tr->numBranches; i++)
searchAlgo.c:	      tr->currentZQR[i] = tr->zqr[i];           
searchAlgo.c:	      tr->currentLZR[i] = tr->lzr[i];
searchAlgo.c:	      tr->currentLZQ[i] = tr->lzq[i];
searchAlgo.c:	      tr->currentLZS[i] = tr->lzs[i];      
searchAlgo.c:      if(tr->likelihood > tr->endLH)
searchAlgo.c:	  tr->insertNode = q;
searchAlgo.c:	  tr->removeNode = p;   
searchAlgo.c:	  for(i = 0; i < tr->numBranches; i++)
searchAlgo.c:	    tr->currentZQR[i] = tr->zqr[i];      
searchAlgo.c:	  tr->endLH = tr->likelihood;                      
searchAlgo.c:      hookup(q, r, qz, tr->numBranches);
searchAlgo.c:	  hookup(p, s, pz, tr->numBranches);      
searchAlgo.c:      if((tr->doCutoff) && (tr->likelihood < startLH))
searchAlgo.c:	  tr->lhAVG += (startLH - tr->likelihood);
searchAlgo.c:	  tr->lhDEC++;
searchAlgo.c:	  if((startLH - tr->likelihood) >= tr->lhCutoff)
searchAlgo.c:  if ((!isTip(q->number, tr->mxtips)) && (--maxtrav > 0)) 
searchAlgo.c:  if (!isTip(p->number, tr->mxtips) && doP) 
searchAlgo.c:      if(!isTip(p1->number, tr->mxtips) || !isTip(p2->number, tr->mxtips))
searchAlgo.c:	  for(i = 0; i < tr->numBranches; i++)
searchAlgo.c:	  if (! removeNodeBIG(tr, p,  tr->numBranches)) return badRear;
searchAlgo.c:	  if (!isTip(p1->number, tr->mxtips)) 
searchAlgo.c:	  if (!isTip(p2->number, tr->mxtips)) 
searchAlgo.c:	  hookup(p->next,       p1, p1z, tr->numBranches); 
searchAlgo.c:	  hookup(p->next->next, p2, p2z, tr->numBranches);	   	    	    
searchAlgo.c:  if (!isTip(q->number, tr->mxtips) && maxtrav > 0 && doQ) 
searchAlgo.c:	   ! isTip(q1->number, tr->mxtips) && 
searchAlgo.c:	   (! isTip(q1->next->back->number, tr->mxtips) || ! isTip(q1->next->next->back->number, tr->mxtips))
searchAlgo.c:	   ! isTip(q2->number, tr->mxtips) && 
searchAlgo.c:	   (! isTip(q2->next->back->number, tr->mxtips) || ! isTip(q2->next->next->back->number, tr->mxtips))
searchAlgo.c:	  for(i = 0; i < tr->numBranches; i++)
searchAlgo.c:	  if (! removeNodeBIG(tr, q, tr->numBranches)) return badRear;
searchAlgo.c:	  if (/*! q1->tip*/ !isTip(q1->number, tr->mxtips)) 
searchAlgo.c:	  if (/*! q2->tip*/ ! isTip(q2->number, tr->mxtips)) 
searchAlgo.c:	  hookup(q->next,       q1, q1z, tr->numBranches); 
searchAlgo.c:	  hookup(q->next->next, q2, q2z, tr->numBranches);
searchAlgo.c:  if (maxtrav > tr->mxtips - 3)  
searchAlgo.c:    maxtrav = tr->mxtips - 3;  
searchAlgo.c:  tr->startLH = tr->endLH = tr->likelihood;
searchAlgo.c:  if(tr->doCutoff)
searchAlgo.c:      if(tr->bigCutoff)
searchAlgo.c:	  if(tr->itCount == 0)    
searchAlgo.c:	    tr->lhCutoff = 0.5 * (tr->likelihood / -1000.0);    
searchAlgo.c:	    tr->lhCutoff = 0.5 * ((tr->lhAVG) / ((double)(tr->lhDEC))); 	  
searchAlgo.c:	  if(tr->itCount == 0)    
searchAlgo.c:	    tr->lhCutoff = tr->likelihood / -1000.0;    
searchAlgo.c:	    tr->lhCutoff = (tr->lhAVG) / ((double)(tr->lhDEC));   
searchAlgo.c:      tr->itCount = tr->itCount + 1;
searchAlgo.c:      tr->lhAVG = 0;
searchAlgo.c:      tr->lhDEC = 0;
searchAlgo.c:    printf("DoCutoff: %d\n", tr->doCutoff);
searchAlgo.c:    printf("%d %f %f %f\n", tr->itCount, tr->lhAVG, tr->lhDEC, tr->lhCutoff);
searchAlgo.c:  for(i = 1; i <= tr->mxtips + tr->mxtips - 2; i++)
searchAlgo.c:      tr->bestOfNode = unlikely;          
searchAlgo.c:      if(rearrangeBIG(tr, tr->nodep[index], mintrav, maxtrav))
searchAlgo.c:	      if(tr->endLH > tr->startLH)                 	
searchAlgo.c:		  tr->startLH = tr->endLH = tr->likelihood;	 
searchAlgo.c:		  if(tr->saveBestTrees)
searchAlgo.c:		  if(tr->bestOfNode != unlikely)		    	     
searchAlgo.c:	      insertInfoList(tr->nodep[index], tr->bestOfNode);	    
searchAlgo.c:	      if(tr->endLH > tr->startLH)                 	
searchAlgo.c:		  tr->startLH = tr->endLH = tr->likelihood;	  	 	  	  	  	  	  	  
searchAlgo.c:	  tr->bestOfNode = unlikely;
searchAlgo.c:	      if(tr->endLH > tr->startLH)                 	
searchAlgo.c:		  tr->startLH = tr->endLH = tr->likelihood;	 
searchAlgo.c:		  if(tr->saveBestTrees)
searchAlgo.c:		  if(tr->bestOfNode != unlikely)
searchAlgo.c:  return tr->startLH;     
searchAlgo.c:      if (! insertBIG(tr, p, q, tr->numBranches))       return FALSE;    
searchAlgo.c:	if(! isTip(x->number, tr->mxtips) && isTip(y->number, tr->mxtips))
searchAlgo.c:	if(isTip(x->number, tr->mxtips) && !isTip(y->number, tr->mxtips))
searchAlgo.c:	if(!isTip(x->number, tr->mxtips) && !isTip(y->number, tr->mxtips))
searchAlgo.c:      tr->likelihood = tr->endLH;
searchAlgo.c:  removeNodeRestoreBIG(tr, tr->removeNode);    
searchAlgo.c:  testInsertRestoreBIG(tr, tr->removeNode, tr->insertNode);
searchAlgo.c:    x = tr->mxtips + 3 * (tr->mxtips - 1);
searchAlgo.c:    base = tr->nodeBaseAddress;
searchAlgo.c:  myBinFwrite(&(tr->start->number), sizeof(int), 1, f);
searchAlgo.c:  myBinFwrite(tr->nodeBaseAddress, sizeof(node), x, f);
searchAlgo.c:      *rateCategory_result = (int*)calloc((size_t)tr->originalCrunchedLength , sizeof(int));
searchAlgo.c:      *patrat_result       = (double*)calloc((size_t)tr->originalCrunchedLength, sizeof(double));
searchAlgo.c:  gatherDistributedArray(tr, (void**) patrat_result,  tr->patrat_basePtr, MPI_DOUBLE , countPerProc, displPerProc); 
searchAlgo.c:  gatherDistributedArray(tr, (void**) rateCategory_result, tr->rateCategory_basePtr, MPI_INT, countPerProc, displPerProc ); 
searchAlgo.c:  ckp.cmd.useMedian = tr->useMedian;
searchAlgo.c:  ckp.cmd.saveBestTrees = tr->saveBestTrees;
searchAlgo.c:  ckp.cmd.saveMemory = tr->saveMemory;
searchAlgo.c:  ckp.cmd.searchConvergenceCriterion = tr->searchConvergenceCriterion;
searchAlgo.c:  ckp.cmd.categories =  tr->categories;
searchAlgo.c:  ckp.cmd.fastTreeEvaluation =  tr->fastTreeEvaluation;
searchAlgo.c:  ckp.cmd.rateHetModel = tr->rateHetModel;
searchAlgo.c:  ckp.cmd.autoProteinSelectionType = tr->autoProteinSelectionType;
searchAlgo.c:  ckp.constraintTree = tr->constraintTree;
searchAlgo.c:  if(tr->constraintTree)
searchAlgo.c:    myBinFwrite(tr->constraintVector, sizeof(int), 2 * tr->mxtips, f);  
searchAlgo.c:  myBinFwrite(tr->tree0, sizeof(char), tr->treeStringLength, f);
searchAlgo.c:  myBinFwrite(tr->tree1, sizeof(char), tr->treeStringLength, f);
searchAlgo.c:  if(tr->rateHetModel == CAT)
searchAlgo.c:      myBinFwrite(rateCategory, sizeof(int), tr->originalCrunchedLength, f);
searchAlgo.c:      myBinFwrite(patrat, sizeof(double), tr->originalCrunchedLength, f);
searchAlgo.c:  myBinFwrite(tr->fracchanges,  sizeof(double), tr->NumberOfModels, f);
searchAlgo.c:  myBinFwrite(&(tr->fracchange),   sizeof(double), 1, f);
searchAlgo.c:  myBinFwrite(tr->rawFracchanges,  sizeof(double), tr->NumberOfModels, f);
searchAlgo.c:  myBinFwrite(&(tr->rawFracchange),   sizeof(double), 1, f);
searchAlgo.c:  for(model = 0; model < tr->NumberOfModels; model++)
searchAlgo.c:	dataType = tr->partitionData[model].dataType;
searchAlgo.c:      myBinFwrite(&(tr->partitionData[model].numberOfCategories), sizeof(int), 1, f);
searchAlgo.c:      myBinFwrite(tr->partitionData[model].perSiteRates, sizeof(double), tr->maxCategories, f);
searchAlgo.c:      myBinFwrite(tr->partitionData[model].EIGN, sizeof(double), pLengths[dataType].eignLength, f);
searchAlgo.c:      myBinFwrite(tr->partitionData[model].EV, sizeof(double),  pLengths[dataType].evLength, f);
searchAlgo.c:      myBinFwrite(tr->partitionData[model].EI, sizeof(double),  pLengths[dataType].eiLength, f);  
searchAlgo.c:      myBinFwrite(tr->partitionData[model].freqExponents, sizeof(double),  pLengths[dataType].frequenciesLength, f);
searchAlgo.c:      myBinFwrite(tr->partitionData[model].frequencies,   sizeof(double),  pLengths[dataType].frequenciesLength, f);
searchAlgo.c:      myBinFwrite(tr->partitionData[model].tipVector,     sizeof(double),  pLengths[dataType].tipVectorLength, f);       
searchAlgo.c:      myBinFwrite(tr->partitionData[model].substRates, sizeof(double),  pLengths[dataType].substRatesLength, f);
searchAlgo.c:      myBinFwrite(tr->partitionData[model].weights , sizeof(double), 4, f);
searchAlgo.c:      myBinFwrite(tr->partitionData[model].weightExponents , sizeof(double), 4, f);
searchAlgo.c:      //myBinFwrite(tr->partitionData[model].weightsBuffer , sizeof(double), 4, f);
searchAlgo.c:      //myBinFwrite(tr->partitionData[model].weightExponentsBuffer , sizeof(double), 4, f);
searchAlgo.c:      if(tr->partitionData[model].protModels == LG4M || tr->partitionData[model].protModels == LG4X)
searchAlgo.c:	      myBinFwrite(tr->partitionData[model].EIGN_LG4[k], sizeof(double), pLengths[dataType].eignLength, f);
searchAlgo.c:	      myBinFwrite(tr->partitionData[model].EV_LG4[k], sizeof(double),  pLengths[dataType].evLength, f);
searchAlgo.c:	      myBinFwrite(tr->partitionData[model].EI_LG4[k], sizeof(double),  pLengths[dataType].eiLength, f);    
searchAlgo.c:	      myBinFwrite(tr->partitionData[model].frequencies_LG4[k], sizeof(double),  pLengths[dataType].frequenciesLength, f);
searchAlgo.c:	      myBinFwrite(tr->partitionData[model].tipVector_LG4[k], sizeof(double),  pLengths[dataType].tipVectorLength, f);  
searchAlgo.c:	      myBinFwrite(tr->partitionData[model].substRates_LG4[k], sizeof(double),  pLengths[dataType].substRatesLength, f);    
searchAlgo.c:      myBinFwrite(&(tr->partitionData[model].alpha), sizeof(double), 1, f);
searchAlgo.c:      myBinFwrite(&(tr->partitionData[model].gammaRates), sizeof(double), 4, f);
searchAlgo.c:      myBinFwrite(&(tr->partitionData[model].protModels), sizeof(int), 1, f);
searchAlgo.c:      myBinFwrite(&(tr->partitionData[model].autoProtModels), sizeof(int), 1, f);
searchAlgo.c:      myBinFwrite(tr->likelihoods, sizeof(double), tr->numberOfTrees, f);
searchAlgo.c:      myBinFwrite(tr->treeStrings, sizeof(char), (size_t)tr->treeStringLength * (size_t)tr->numberOfTrees, f);
searchAlgo.c:  /* printBothOpen("\nCheckpoint written to: %s likelihood: %f\n", extendedName, tr->likelihood); */
searchAlgo.c:  if(tr->rateHetModel == CAT)
searchAlgo.c:      if(tr->rateHetModel == CAT)
searchAlgo.c:    x = tr->mxtips + 3 * (tr->mxtips - 1);
searchAlgo.c:  tr->start = tr->nodep[nodeNumber];
searchAlgo.c:  /*printf("Start: %d %d\n", tr->start->number, nodeNumber);*/
searchAlgo.c:  /*printf("%u %u\n", (size_t)startAddress, (size_t)tr->nodeBaseAddress);*/
searchAlgo.c:  myBinFread(tr->nodeBaseAddress, sizeof(node), x, f);
searchAlgo.c:    if(startAddress > tr->nodeBaseAddress)
searchAlgo.c:	offset = (size_t)startAddress - (size_t)tr->nodeBaseAddress;
searchAlgo.c:	offset = (size_t)tr->nodeBaseAddress - (size_t)startAddress;
searchAlgo.c:	    tr->nodeBaseAddress[i].next = (nodeptr)((size_t)tr->nodeBaseAddress[i].next + offset);	
searchAlgo.c:	    tr->nodeBaseAddress[i].back = (nodeptr)((size_t)tr->nodeBaseAddress[i].back + offset);
searchAlgo.c:	   tr->nodeBaseAddress[i].next = (nodeptr)((size_t)tr->nodeBaseAddress[i].next - offset);	
searchAlgo.c:	   tr->nodeBaseAddress[i].back = (nodeptr)((size_t)tr->nodeBaseAddress[i].back - offset);	   
searchAlgo.c:  evaluateGeneric(tr, tr->start, TRUE);  
searchAlgo.c:  printBothOpen("ExaML Restart with likelihood: %1.50f\n", tr->likelihood);
searchAlgo.c:  if(ckp.cmd.useMedian != tr->useMedian)
searchAlgo.c:  if(ckp.cmd.saveBestTrees != tr->saveBestTrees)
searchAlgo.c:  if(ckp.cmd.saveMemory != tr->saveMemory)
searchAlgo.c:  if(ckp.cmd.searchConvergenceCriterion != tr->searchConvergenceCriterion)
searchAlgo.c:  if(ckp.cmd.categories !=  tr->categories)
searchAlgo.c:  if(ckp.cmd.fastTreeEvaluation !=  tr->fastTreeEvaluation)
searchAlgo.c:  if(ckp.cmd.rateHetModel != tr->rateHetModel)
searchAlgo.c:   if(ckp.cmd.autoProteinSelectionType != tr->autoProteinSelectionType)
searchAlgo.c:  tr->constraintTree = ckp.constraintTree;
searchAlgo.c:  if(tr->constraintTree)
searchAlgo.c:    myBinFread(tr->constraintVector, sizeof(int), 2 * tr->mxtips, f);  
searchAlgo.c:  tr->ntips = tr->mxtips;
searchAlgo.c:  tr->startLH    = ckp.tr_startLH;
searchAlgo.c:  tr->endLH      = ckp.tr_endLH;
searchAlgo.c:  tr->likelihood = ckp.tr_likelihood;
searchAlgo.c:  tr->bestOfNode = ckp.tr_bestOfNode;
searchAlgo.c:  tr->lhCutoff   = ckp.tr_lhCutoff;
searchAlgo.c:  tr->lhAVG      = ckp.tr_lhAVG;
searchAlgo.c:  tr->lhDEC      = ckp.tr_lhDEC;
searchAlgo.c:  tr->itCount    = ckp.tr_itCount;
searchAlgo.c:  myBinFread(tr->tree0, sizeof(char), tr->treeStringLength, f);
searchAlgo.c:  myBinFread(tr->tree1, sizeof(char), tr->treeStringLength, f);
searchAlgo.c:  if(tr->searchConvergenceCriterion && processID == 0)
searchAlgo.c:	  treeReadTopologyString(tr->tree0, tr);   
searchAlgo.c:	  bitVectorInitravSpecial(tr->bitVectors, tr->nodep[1]->back, tr->mxtips, tr->vLength, tr->h, 0, BIPARTITIONS_RF, (branchInfo *)NULL,
searchAlgo.c:	  assert(bCounter == tr->mxtips - 3);
searchAlgo.c:	  treeReadTopologyString(tr->tree1, tr); 
searchAlgo.c:	  bitVectorInitravSpecial(tr->bitVectors, tr->nodep[1]->back, tr->mxtips, tr->vLength, tr->h, 1, BIPARTITIONS_RF, (branchInfo *)NULL,
searchAlgo.c:	  assert(bCounter == tr->mxtips - 3);
searchAlgo.c:  if(tr->rateHetModel == CAT )
searchAlgo.c:      /* Andre I think tr->originalCrunchedLength is of type size_t???
searchAlgo.c:	pPos  = rPos + sizeof(int) * tr->originalCrunchedLength; 
searchAlgo.c:      Assign *aIter =  tr->partAssigns,
searchAlgo.c:	*aEnd = &(tr->partAssigns [ tr->numAssignments ]) ; 
searchAlgo.c:		*partition = &(tr->partitionData[aIter->partitionId]); 
searchAlgo.c:      exa_fseek(f, pPos + tr->originalCrunchedLength * sizeof(double) , SEEK_SET); 
searchAlgo.c:  myBinFread(tr->fracchanges,  sizeof(double), tr->NumberOfModels, f);
searchAlgo.c:  myBinFread(&(tr->fracchange),   sizeof(double), 1, f);
searchAlgo.c:  myBinFread(tr->rawFracchanges,  sizeof(double), tr->NumberOfModels, f);
searchAlgo.c:  myBinFread(&(tr->rawFracchange),   sizeof(double), 1, f);
searchAlgo.c:  for(model = 0; model < tr->NumberOfModels; model++)
searchAlgo.c:	dataType = tr->partitionData[model].dataType;
searchAlgo.c:      myBinFread(&(tr->partitionData[model].numberOfCategories), sizeof(int), 1, f);
searchAlgo.c:      myBinFread(tr->partitionData[model].perSiteRates, sizeof(double), tr->maxCategories, f);
searchAlgo.c:      myBinFread(tr->partitionData[model].EIGN, sizeof(double), pLengths[dataType].eignLength, f);
searchAlgo.c:      myBinFread(tr->partitionData[model].EV, sizeof(double),  pLengths[dataType].evLength, f);
searchAlgo.c:      myBinFread(tr->partitionData[model].EI, sizeof(double),  pLengths[dataType].eiLength, f);  
searchAlgo.c:      myBinFread(tr->partitionData[model].freqExponents, sizeof(double),  pLengths[dataType].frequenciesLength, f);
searchAlgo.c:      myBinFread(tr->partitionData[model].frequencies, sizeof(double),  pLengths[dataType].frequenciesLength, f);
searchAlgo.c:      myBinFread(tr->partitionData[model].tipVector, sizeof(double),  pLengths[dataType].tipVectorLength, f);  
searchAlgo.c:      myBinFread(tr->partitionData[model].substRates, sizeof(double),  pLengths[dataType].substRatesLength, f);  
searchAlgo.c:      myBinFread(tr->partitionData[model].weights , sizeof(double), 4, f);
searchAlgo.c:      myBinFread(tr->partitionData[model].weightExponents , sizeof(double), 4, f);
searchAlgo.c:      //myBinFread(tr->partitionData[model].weightsBuffer , sizeof(double), 4, f);
searchAlgo.c:      //myBinFread(tr->partitionData[model].weightExponentsBuffer , sizeof(double), 4, f);
searchAlgo.c:      if(tr->partitionData[model].protModels == LG4X || tr->partitionData[model].protModels == LG4M)
searchAlgo.c:	      myBinFread(tr->partitionData[model].EIGN_LG4[k], sizeof(double), pLengths[dataType].eignLength, f);
searchAlgo.c:	      myBinFread(tr->partitionData[model].EV_LG4[k], sizeof(double),  pLengths[dataType].evLength, f);
searchAlgo.c:	      myBinFread(tr->partitionData[model].EI_LG4[k], sizeof(double),  pLengths[dataType].eiLength, f);    
searchAlgo.c:	      myBinFread(tr->partitionData[model].frequencies_LG4[k], sizeof(double),  pLengths[dataType].frequenciesLength, f);
searchAlgo.c:	      myBinFread(tr->partitionData[model].tipVector_LG4[k], sizeof(double),  pLengths[dataType].tipVectorLength, f);  
searchAlgo.c:	      myBinFread(tr->partitionData[model].substRates_LG4[k], sizeof(double),  pLengths[dataType].substRatesLength, f);    
searchAlgo.c:      myBinFread(&(tr->partitionData[model].alpha), sizeof(double), 1, f);      
searchAlgo.c:      myBinFread(&(tr->partitionData[model].gammaRates), sizeof(double), 4, f);
searchAlgo.c:      if(tr->rateHetModel != CAT && !(tr->partitionData[model].protModels == LG4X))
searchAlgo.c:	makeGammaCats(tr->partitionData[model].alpha, tr->partitionData[model].gammaRates, 4, tr->useMedian); 
searchAlgo.c:      myBinFread(&(tr->partitionData[model].protModels), sizeof(int), 1, f);
searchAlgo.c:      myBinFread(&(tr->partitionData[model].autoProtModels), sizeof(int), 1, f);
searchAlgo.c:      myBinFread(tr->likelihoods, sizeof(double), tr->numberOfTrees, f);
searchAlgo.c:      myBinFread(tr->treeStrings, sizeof(char), (size_t)tr->treeStringLength * (size_t)tr->numberOfTrees, f);
searchAlgo.c:  if(tr->rateHetModel == CAT)
searchAlgo.c:    startLH = tr->likelihood; 
searchAlgo.c:    cutoff = tr->doCutoff;
searchAlgo.c:  tr->doCutoff = FALSE;      
searchAlgo.c:	ckp.tr_startLH  = tr->startLH;
searchAlgo.c:	ckp.tr_endLH    = tr->endLH;
searchAlgo.c:	ckp.tr_likelihood = tr->likelihood;
searchAlgo.c:	ckp.tr_bestOfNode = tr->bestOfNode;
searchAlgo.c:	ckp.tr_lhCutoff = tr->lhCutoff;
searchAlgo.c:	ckp.tr_lhAVG    = tr->lhAVG;
searchAlgo.c:	ckp.tr_lhDEC    = tr->lhDEC;      
searchAlgo.c:	ckp.tr_itCount  = tr->itCount;
searchAlgo.c:      if (maxtrav > tr->mxtips - 3)  
searchAlgo.c:	maxtrav = tr->mxtips - 3;    
searchAlgo.c:      tr->startLH = tr->endLH = tr->likelihood;
searchAlgo.c:      /* printBothOpen("TRAV: %d lh %f MNZC %d\n", maxtrav, tr->likelihood, mnzc); */
searchAlgo.c:	for(i = 1; i <= tr->mxtips + tr->mxtips - 2; i++)
searchAlgo.c:	    tr->bestOfNode = unlikely;
searchAlgo.c:	    if(rearrangeBIG(tr, tr->nodep[i], 1, maxtrav))
searchAlgo.c:		if(tr->endLH > tr->startLH)                 	
searchAlgo.c:		    tr->startLH = tr->endLH = tr->likelihood;			  
searchAlgo.c:	  evaluateGeneric(tr, tr->start, TRUE);	
searchAlgo.c:	  printBothOpen("Changes: %d TRAV: %d lh %f MNZC %d\n", changes, maxtrav, tr->likelihood, mnzc);
searchAlgo.c:      /* printBothOpen("TRAV: %d lh %f MNZC %d\n", maxtrav, tr->likelihood, mnzc); */
searchAlgo.c:      if(tr->saveBestTrees)
searchAlgo.c:      printBothOpen("TRAV: %d lh %f MNZC %d\n", maxtrav, tr->likelihood, mnzc);
searchAlgo.c:      if(tr->likelihood > startLH)
searchAlgo.c:	  startLH = tr->likelihood; 	  	  	  
searchAlgo.c:      if(tr->doCutoff)
searchAlgo.c:	  tr->lhCutoff = (tr->lhAVG) / ((double)(tr->lhDEC));       
searchAlgo.c:	  tr->itCount =  tr->itCount + 1;
searchAlgo.c:	  tr->lhAVG = 0;
searchAlgo.c:	  tr->lhDEC = 0;
searchAlgo.c:  tr->doCutoff = cutoff; 
searchAlgo.c:  tr->lhAVG = 0.0;
searchAlgo.c:  tr->lhDEC = 0.0;
searchAlgo.c:  if(tr->searchConvergenceCriterion && processID == 0)   
searchAlgo.c:  initBestTree(bestT, 1, tr->mxtips);
searchAlgo.c:  initBestTree(bt, 20, tr->mxtips);    
searchAlgo.c:  if(tr->saveBestTrees > 0)
searchAlgo.c:      initBestTree(bestML, tr->saveBestTrees, tr->mxtips);  
searchAlgo.c:  if(tr->doCutoff)
searchAlgo.c:    tr->itCount = 0;
searchAlgo.c:	  tr->likelihood = ckp.tr_likelihood;
searchAlgo.c:	  tr->lhCutoff = ckp.tr_lhCutoff;
searchAlgo.c:	  tr->lhAVG    = ckp.tr_lhAVG;
searchAlgo.c:	  tr->lhDEC    = ckp.tr_lhDEC;   	 
searchAlgo.c:	  tr->itCount = ckp.tr_itCount;	  
searchAlgo.c:	ckp.tr_startLH  = tr->startLH;
searchAlgo.c:	ckp.tr_endLH    = tr->endLH;
searchAlgo.c:	ckp.tr_likelihood = tr->likelihood;
searchAlgo.c:	ckp.tr_bestOfNode = tr->bestOfNode;
searchAlgo.c:	ckp.tr_lhCutoff = tr->lhCutoff;
searchAlgo.c:	ckp.tr_lhAVG    = tr->lhAVG;
searchAlgo.c:	ckp.tr_lhDEC    = tr->lhDEC;       
searchAlgo.c:	ckp.tr_itCount  = tr->itCount;       
searchAlgo.c:      if(tr->searchConvergenceCriterion && processID == 0)
searchAlgo.c:	    *buffer = (char*)calloc(tr->treeStringLength, sizeof(char));	  	      	 	  	  	
searchAlgo.c:	    cleanupHashTable(tr->h, (fastIterations % 2));		
searchAlgo.c:	  bitVectorInitravSpecial(tr->bitVectors, tr->nodep[1]->back, tr->mxtips, tr->vLength, tr->h, fastIterations % 2, BIPARTITIONS_RF, (branchInfo *)NULL,
searchAlgo.c:	  Tree2String(buffer, tr, tr->start->back, FALSE, TRUE, FALSE, FALSE, FALSE, SUMMARIZE_LH, FALSE, FALSE);
searchAlgo.c:	    memcpy(tr->tree0, buffer, tr->treeStringLength * sizeof(char));
searchAlgo.c:	    memcpy(tr->tree1, buffer, tr->treeStringLength * sizeof(char));	    
searchAlgo.c:	  assert(bCounter == tr->mxtips - 3);	    	   	  	 
searchAlgo.c:		rrf = convergenceCriterion(tr->h, tr->mxtips);
searchAlgo.c:		  cleanupHashTable(tr->h, 0);
searchAlgo.c:		  cleanupHashTable(tr->h, 1);
searchAlgo.c:      if(tr->searchConvergenceCriterion && processID != 0 && fastIterations > 0)
searchAlgo.c:      lh = previousLh = tr->likelihood;
searchAlgo.c:	  difference = ((tr->likelihood > previousLh)? 
searchAlgo.c:			tr->likelihood - previousLh: 
searchAlgo.c:			previousLh - tr->likelihood); 	    
searchAlgo.c:	  if(tr->likelihood > lh && difference > epsilon)
searchAlgo.c:	      lh = tr->likelihood;	       	     
searchAlgo.c:  if(tr->searchConvergenceCriterion && processID == 0)
searchAlgo.c:      cleanupHashTable(tr->h, 0);
searchAlgo.c:      cleanupHashTable(tr->h, 1);
searchAlgo.c:  evaluateGeneric(tr, tr->start, TRUE);
searchAlgo.c:  printBothOpen("After Fast SPRs Final %f\n", tr->likelihood);   
searchAlgo.c:	  tr->likelihood = ckp.tr_likelihood;
searchAlgo.c:	  tr->lhCutoff = ckp.tr_lhCutoff;
searchAlgo.c:	  tr->lhAVG    = ckp.tr_lhAVG;
searchAlgo.c:	  tr->lhDEC    = ckp.tr_lhDEC;   	 
searchAlgo.c:	  tr->itCount = ckp.tr_itCount;	 
searchAlgo.c:	  ckp.tr_startLH  = tr->startLH;
searchAlgo.c:	  ckp.tr_endLH    = tr->endLH;
searchAlgo.c:	  ckp.tr_likelihood = tr->likelihood;
searchAlgo.c:	  ckp.tr_bestOfNode = tr->bestOfNode;
searchAlgo.c:	  ckp.tr_lhCutoff = tr->lhCutoff;
searchAlgo.c:	  ckp.tr_lhAVG    = tr->lhAVG;
searchAlgo.c:	  ckp.tr_lhDEC    = tr->lhDEC;     
searchAlgo.c:	  ckp.tr_itCount  = tr->itCount;	
searchAlgo.c:	  if(tr->searchConvergenceCriterion && processID == 0)
searchAlgo.c:		*buffer = (char*)calloc(tr->treeStringLength, sizeof(char));   
searchAlgo.c:		cleanupHashTable(tr->h, (thoroughIterations % 2));		
searchAlgo.c:	      bitVectorInitravSpecial(tr->bitVectors, tr->nodep[1]->back, tr->mxtips, tr->vLength, tr->h, thoroughIterations % 2, BIPARTITIONS_RF, (branchInfo *)NULL,
searchAlgo.c:	      Tree2String(buffer, tr, tr->start->back, FALSE, TRUE, FALSE, FALSE, FALSE, SUMMARIZE_LH, FALSE, FALSE);
searchAlgo.c:		memcpy(tr->tree0, buffer, tr->treeStringLength * sizeof(char));
searchAlgo.c:		memcpy(tr->tree1, buffer, tr->treeStringLength * sizeof(char));	    
searchAlgo.c:	      assert(bCounter == tr->mxtips - 3);
searchAlgo.c:		    rrf = convergenceCriterion(tr->h, tr->mxtips);
searchAlgo.c:	  if(tr->searchConvergenceCriterion && processID != 0 && thoroughIterations > 0)
searchAlgo.c:      previousLh = lh = tr->likelihood;	      
searchAlgo.c:	  difference = ((tr->likelihood > previousLh)? 
searchAlgo.c:			tr->likelihood - previousLh: 
searchAlgo.c:			previousLh - tr->likelihood); 	    
searchAlgo.c:	  if(tr->likelihood > lh && difference > epsilon)
searchAlgo.c:	      lh = tr->likelihood;	  	     
searchAlgo.c:  evaluateGeneric(tr, tr->start, TRUE);
searchAlgo.c:  printBothOpen("After SLOW SPRs Final %f\n", tr->likelihood);   
searchAlgo.c:  printBothOpen("\nLikelihood of best tree: %f\n", tr->likelihood);
searchAlgo.c:  if(tr->saveBestTrees > 0)
searchAlgo.c:	  printBothOpen("tree %d likelihood %1.80f\n", i, tr->likelihood);
searchAlgo.c:	      Tree2String(tr->tree_string, tr, tr->start->back, TRUE, TRUE, FALSE, FALSE, TRUE, SUMMARIZE_LH, FALSE, FALSE);
searchAlgo.c:	      fprintf(treeFile, "%s", tr->tree_string);
searchAlgo.c:  if(tr->searchConvergenceCriterion && processID == 0)
searchAlgo.c:      freeBitVectors(tr->bitVectors, 2 * tr->mxtips);
searchAlgo.c:      free(tr->bitVectors);
searchAlgo.c:      freeHashTable(tr->h);
searchAlgo.c:      free(tr->h);
searchAlgo.c:  evaluateGeneric(tr, tr->start, TRUE);   
topologies.c:	  if(tr->constraintTree)
topologies.c:	      tpl->connect[*i].cp = tr->constraintVector[q->number];
topologies.c:	      tpl->connect[*i].cq = tr->constraintVector[q->back->number]; 
topologies.c:  nodeptr p = tr->start;
topologies.c:  tpl->likelihood = tr->likelihood;
topologies.c:  if(tr->constraintTree)
topologies.c:      tpl->connect[i].cp = tr->constraintVector[p->number];
topologies.c:      tpl->connect[i].cq = tr->constraintVector[p->back->number]; 
topologies.c:  for(k = 0; k < tr->numBranches; k++)
topologies.c:  saveTopolRELLRec(tr, p->back, tpl, &i, tr->mxtips, tr->numBranches);   
topologies.c:  assert(i == 2 * tr->mxtips - 3);
topologies.c:  for (i = 0; i < 2 * tr->mxtips - 3; i++) 
topologies.c:      hookup(tpl->connect[i].p, tpl->connect[i].q, tpl->connect[i].z,  tr->numBranches);    
topologies.c:      tr->constraintVector[tpl->connect[i].p->number] = tpl->connect[i].cp;
topologies.c:      tr->constraintVector[tpl->connect[i].q->number] = tpl->connect[i].cq;
topologies.c:  tr->likelihood = tpl->likelihood;
topologies.c:  tr->start      = tr->nodep[tpl->start];
topologies.c:      rl->t[i]->connect = (connectRELL *)malloc((2 * tr->mxtips - 3) * sizeof(connectRELL));
topologies.c:  if(tr->likelihood > rl->t[index]->likelihood)        
topologies.c:  r = tpl->links + saveSubtree(minTreeTip(tr->start, tr->mxtips), tpl, tr->mxtips, tr->numBranches);  /* Save tree */
topologies.c:  tpl->likelihood = tr->likelihood;
topologies.c:  tpl->start      = tr->start;
topologies.c:  tpl->ntips      = tr->ntips;
topologies.c:  tpl->nextnode   = tr->nextnode;    
topologies.c:  for (i = 1; i <= 2*(tr->mxtips) - 2; i++) 
topologies.c:      p0 = p = tr->nodep[i];
topologies.c:    hookup(r->p, r->q, r->z, tr->numBranches);      
topologies.c:  tr->likelihood = tpl->likelihood;
topologies.c:  tr->start      = tpl->start;
topologies.c:  tr->ntips      = tpl->ntips;
topologies.c:  tr->nextnode   = tpl->nextnode;    
topologies.c:  evaluateGeneric(tr, tr->start, TRUE);
topologies.c:      if(tr->likelihood < bt->worst)  
topologies.c:	  if (tr->likelihood > bt->start->likelihood) 
topologies.c:  if (scrNum == 1)  bt->best = tr->likelihood;
trash.c:  if(isTip(p->number, tr->mxtips))    
trash.c:      for(i = tr->mxtips + 1; (i <= (tr->mxtips + tr->mxtips - 1)) && (found == 0); i++)
trash.c:		tr->nodep[*count + tr->mxtips + 1] = np[i];		 		
trash.c:		    tr->nodep[*count + tr->mxtips + 1] = np[i]->next;		     	   
trash.c:		    tr->nodep[*count + tr->mxtips + 1] = np[i]->next->next;		    		    
trash.c:  nodeptr *np = (nodeptr *)malloc(2 * tr->mxtips * sizeof(nodeptr));
trash.c:  tr->start       = tr->nodep[1];
trash.c:  tr->rooted      = FALSE;
trash.c:  /* TODO why is tr->rooted set to FALSE here ?*/
trash.c:  for(i = tr->mxtips + 1; i <= (tr->mxtips + tr->mxtips - 1); i++)
trash.c:    np[i] = tr->nodep[i];           
trash.c:  reorderNodes(tr, np, tr->start->back, &count); 
treeIO.c:  if(tr->numBranches == 1)
treeIO.c:      assert(tr->fracchange != -1.0);
treeIO.c:      x = -log(z) * tr->fracchange;  
treeIO.c:      /* printf("%f %f %f\n", tr->fracchange, x, z);           */
treeIO.c:	  for(i = 0; i < tr->numBranches; i++)
treeIO.c:	      assert(tr->partitionContributions[i] != -1.0);
treeIO.c:	      assert(tr->fracchanges[i] != -1.0);
treeIO.c:	      x = -log(z) * tr->fracchanges[i];
treeIO.c:	      avgX += x * tr->partitionContributions[i];
treeIO.c:	  assert(tr->fracchanges[perGene] != -1.0);
treeIO.c:	  assert(perGene >= 0 && perGene < tr->numBranches);
treeIO.c:	  x = -log(z) * tr->fracchanges[perGene];	  
treeIO.c:  if(isTip(p->number, tr->mxtips)) 
treeIO.c:	  nameptr = tr->nameList[p->number];     
treeIO.c:      if(p == tr->start->back) 
treeIO.c:  if(p == tr->start->back) 
treeIO.c:	  if(( !isTip(p->number, tr->mxtips)) && 
treeIO.c:	     ( !isTip(p->back->number, tr->mxtips)))
treeIO.c:  for(i = 0; i < tr->numBranches; i++)	
treeIO.c:      Tree2String(tr->tree_string, tr, tr->start->back, TRUE, TRUE, FALSE, FALSE, TRUE, i, FALSE, FALSE);
treeIO.c:      fprintf(treeFile, "%s", tr->tree_string);
treeIO.c:  int lookup = lookupWord(str, tr->nameHash);
treeIO.c:      assert(! tr->nodep[lookup]->back);
treeIO.c:      n = (tr->nextnode)++;
treeIO.c:      if (n > 2*(tr->mxtips) - 2) 
treeIO.c:	  if (tr->rooted || n > 2*(tr->mxtips) - 1) 
treeIO.c:	      tr->rooted = TRUE;
treeIO.c:      q = tr->nodep[n];
treeIO.c:	      assert(p->number > tr->mxtips && q->number > tr->mxtips);
treeIO.c:      q = tr->nodep[n];
treeIO.c:      if (tr->start->number > n)  tr->start = q;
treeIO.c:      (tr->ntips)++;
treeIO.c:      /*printf("Branch %8.20f %d\n", branch, tr->numBranches);*/
treeIO.c:      hookup(p, q, &branch, tr->numBranches);
treeIO.c:      hookupDefault(p, q, tr->numBranches);
treeIO.c:  for(i = tr->mxtips + 1; i < 2 * tr->mxtips - 1; i++)
treeIO.c:    assert(i == tr->nodep[i]->number);
treeIO.c:  if(isTip(p->number, tr->mxtips) || p->back) 
treeIO.c:  tr->nextnode = tr->nextnode - 1;
treeIO.c:  assert(tr->nextnode < 2 * tr->mxtips);
treeIO.c:  n = tr->nextnode;               
treeIO.c:  assert(tr->nodep[tr->nextnode]);
treeIO.c:  if (n != tr->mxtips + tr->ntips - 1) 
treeIO.c:      for(i = 0; i < tr->numBranches; i++)
treeIO.c:      hookup (q, r, b, tr->numBranches);
treeIO.c:    hookupDefault(q, r, tr->numBranches);    
treeIO.c:  if(tr->constraintTree)
treeIO.c:      if(tr->constraintVector[p->number] != 0)
treeIO.c:  assert(!(isTip(r->number, tr->mxtips) && isTip(q->number, tr->mxtips))); 
treeIO.c:  assert(p->number > tr->mxtips);
treeIO.c:  if(tr->ntips > 2 && p->number != n) 
treeIO.c:      q = tr->nodep[n];            /* transfer last node's conections to p */
treeIO.c:      if(tr->constraintTree)	
treeIO.c:	tr->constraintVector[p->number] = tr->constraintVector[q->number];       
treeIO.c:      hookup(p,             q->back, q->z, tr->numBranches);   /* move connections to p */
treeIO.c:      hookup(p->next,       r->back, r->z, tr->numBranches);
treeIO.c:      hookup(p->next->next, s->back, s->z, tr->numBranches);           
treeIO.c:  assert(tr->ntips > 2);
treeIO.c:  start = findAnyTip(tr->nodep[tr->mxtips + 1], tr->mxtips);
treeIO.c:  assert(isTip(start->number, tr->mxtips));
treeIO.c:  tr->rooted = FALSE;
treeIO.c:  for (i = 1; i <= tr->mxtips; i++) 
treeIO.c:      tr->nodep[i]->back = (node *) NULL; 
treeIO.c:	tr->nodep[i]->support = -1;*/
treeIO.c:  for(i = tr->mxtips + 1; i < 2 * tr->mxtips; i++)
treeIO.c:      tr->nodep[i]->back = (nodeptr)NULL;
treeIO.c:      tr->nodep[i]->next->back = (nodeptr)NULL;
treeIO.c:      tr->nodep[i]->next->next->back = (nodeptr)NULL;
treeIO.c:      tr->nodep[i]->number = i;
treeIO.c:      tr->nodep[i]->next->number = i;
treeIO.c:      tr->nodep[i]->next->next->number = i;
treeIO.c:	  tr->nodep[i]->support = -2;
treeIO.c:	  tr->nodep[i]->next->support = -2;
treeIO.c:	  tr->nodep[i]->next->next->support = -2;
treeIO.c:    tr->start       = tr->nodep[tr->mxtips];
treeIO.c:    tr->start       = tr->nodep[1];
treeIO.c:  tr->ntips       = 0;
treeIO.c:  tr->nextnode    = tr->mxtips + 1;      
treeIO.c:  for(i = 0; i < tr->numBranches; i++)
treeIO.c:    tr->partitionSmoothed[i] = FALSE;
treeIO.c:  tr->rooted      = FALSE;     
treeIO.c:  p = tr->nodep[(tr->nextnode)++]; 
treeIO.c:  if (! tr->rooted) 
treeIO.c:	  tr->rooted = TRUE;
treeIO.c:    assert(!(tr->rooted && readNodeLabels));
treeIO.c:  if (tr->rooted) 
treeIO.c:      tr->start = uprootTree(tr, p->next->next, FALSE);      
treeIO.c:      if (! tr->start)                              
treeIO.c:    tr->start = findAnyTip(p, tr->mxtips);    
treeIO.c:  assert(tr->ntips == tr->mxtips);
treeIO.c:  tr->constraintVector[p->number] = partitionCounter; 
treeIO.c:      n = (tr->nextnode)++;
treeIO.c:      if (n > 2*(tr->mxtips) - 2) 
treeIO.c:	  if (tr->rooted || n > 2*(tr->mxtips) - 1) 
treeIO.c:	      tr->rooted = TRUE;	    
treeIO.c:      q = tr->nodep[n];
treeIO.c:      tr->constraintVector[q->number] = *partCount;
treeIO.c:      hookupDefault(p, q, tr->numBranches);
treeIO.c:	  n = (tr->nextnode)++;
treeIO.c:	  if (n > 2*(tr->mxtips) - 2) 
treeIO.c:	      if (tr->rooted || n > 2*(tr->mxtips) - 1) 
treeIO.c:		  tr->rooted = TRUE;
treeIO.c:	  r = tr->nodep[n];
treeIO.c:	  tr->constraintVector[r->number] = *partCount;	  
treeIO.c:      q = tr->nodep[n];      
treeIO.c:      tr->constraintVector[q->number] = partitionCounter;
treeIO.c:      if (tr->start->number > n)  tr->start = q;
treeIO.c:      (tr->ntips)++;
treeIO.c:      hookupDefault(p, q, tr->numBranches);
treeIO.c:  srand(tr->randomSeed);
treeIO.c:  for(i = 0; i < 2 * tr->mxtips; i++)
treeIO.c:    tr->constraintVector[i] = -1;
treeIO.c:  for (i = 1; i <= tr->mxtips; i++) 
treeIO.c:    tr->nodep[i]->back = (node *) NULL;
treeIO.c:  for(i = tr->mxtips + 1; i < 2 * tr->mxtips; i++)
treeIO.c:      tr->nodep[i]->back = (nodeptr)NULL;
treeIO.c:      tr->nodep[i]->next->back = (nodeptr)NULL;
treeIO.c:      tr->nodep[i]->next->next->back = (nodeptr)NULL;
treeIO.c:      tr->nodep[i]->number = i;
treeIO.c:      tr->nodep[i]->next->number = i;
treeIO.c:      tr->nodep[i]->next->next->number = i;
treeIO.c:  tr->start       = tr->nodep[tr->mxtips];
treeIO.c:  tr->ntips       = 0;
treeIO.c:  tr->nextnode    = tr->mxtips + 1;
treeIO.c:  for(i = 0; i < tr->numBranches; i++)
treeIO.c:    tr->partitionSmoothed[i] = FALSE;
treeIO.c:  tr->rooted      = FALSE;
treeIO.c:  p = tr->nodep[(tr->nextnode)++]; 
treeIO.c:  if (! tr->rooted) 
treeIO.c:	      n = (tr->nextnode)++;
treeIO.c:	      assert(n <= 2*(tr->mxtips) - 2);
treeIO.c:	      r = tr->nodep[n];	
treeIO.c:	      tr->constraintVector[r->number] = partitionCounter;	   
treeIO.c:	  tr->rooted = TRUE;
treeIO.c:  if (tr->rooted) 
treeIO.c:      tr->start = uprootTree(tr, p->next->next, FALSE);
treeIO.c:      if (! tr->start)                              return FALSE;
treeIO.c:      tr->start = findAnyTip(p, tr->mxtips);
treeIO.c:  assert(tr->ntips == tr->mxtips);
treeIO.c:  tr->likelihood = unlikely;
treeIO.c:  if(tr->constraintTree)
treeIO.c:  tr->start = tr->nodep[1];
